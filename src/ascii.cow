\def[\cppblock{...}]{\codeblock[cpp]{\put}}
\def[\charset{...}]{\html-code{\html-h-[data-h=str]{[\put]}}}
\def[\exposid{...}]{\i{\html-h-[data-h=id]{\put}}}
\def[\ctype]{\exposid{character-type}}
\def[\stable-ref{...}]{\html-span[class=stable-ref]{[\put]}}
\def[\header{...}]{\code[cpp]{\html-h-[data-h=str]{<\put>}}}
\def[\eelis{...}]{\ref[https://eel.is/c++draft/\put]}

\comment{This solely exists to interfere less with TeX highlighting}
\def[\dollar]{\U{24}}
\def[\percent]{\U{25}}

\comment{
    These macros make our wording very similar to C++ draft TeX,
    making the job of the editors much more convenient.
}
\def[\tcode{...}]{\code[cpp]{\put}}
\def[\grammarterm{...}]{\gterm{\put}}
\def[\itemdecl{...}]{\codeblock[cpp,borders=no]{\put}}
\def[\itemdescr{...}]{\indent{\paragraphs{\put}}}
\def[\expects]{\i{Preconditions}:}
\def[\remarks]{\i{Remarks}:}
\def[\returns]{\i{Returns}:}
\def[\recommended]{\i{Recommended practice}:}

\wg21-head[
    title = ASCII character utilities
]{
\dl{
    \dt{Document number:} \dd{\ref[https://wg21.link/P3688R0]{P3688R0}}
    \dt{Date:}            \dd{\tt{2025-05-15}}
    \dt{Audience:}        \dd{LEWG, SG16}
    \dt{Project:}         \dd{ISO/IEC 14882 Programming Languages — C++, ISO/IEC JTC1/SC22/WG21}
    \dt{Author:}          \dd{Jan Schultke <\mail{janschultke@gmail.com}>}
    \dt{Co-Authors:}      \dd{Corentin Jabot <\mail{corentin.jabot@gmail.com}>}
    \dt{GitHub Issue:}    \dd{\ref[https://wg21.link/P3688R0/github]}
    \dt{Source:}          \dd{\ref[https://github.com/Eisenwave/cpp-proposals/blob/master/src/ascii.cow]}
}
\hr
}

\abstract{
The utilities in \header{cctype} or \header{locale}
are locale-specific,
not \tcode{constexpr},
and provide no support for Unicode character types.
We propose lightweight, locale-independent alternatives.
}

\h2[listed=no]{Contents}

\make-contents

\h2{Introduction}

Testing whether a character falls into a specific subset of ASCII characters
or performing some simple transformations are common tasks in text processing.
For example, applications may need to check if identifiers
are comprised of alphanumeric ASCII characters or underscores;
Unicode properties are not relevant to this task,
and usually, neither are locales.

Unfortunately, these common and simple tasks are only supported
through functions in the \header{cctype} and \header{locale} headers, such as:
\cppblock{
// <cctype>
int isalnum(int ch);
int isalpha(int ch);
// ...
int toupper(int ch);

// <locale>
template<class charT> bool isalnum(charT c, const locale& loc); 
}

Especially the \header{cctype} functions are ridden with problems:
\ol{
\item{
    There is no support for Unicode character types
    (\tcode{char8_t}, \tcode{char16_t}, and \tcode{char32_t}).
}
\item{
    These functions are not \tcode{constexpr},
    but performing basic characters tests would be useful at compile time.
}
\item{
    There are distinct function names for \tcode{char} and \tcode{wchar_t}
    such as \tcode{std::isalnum} and \tcode{std::iswalnum},
    making generic programming more difficult.
}
\item{
    If \tcode{char} is signed,
    these functions can easily result in undefined behavior
    because the input must be representable as \tcode{unsigned char} or be \tcode{EOF}.
    If \tcode{char} represents a UTF-8 code unit,
    passing any non-ASCII code unit into these functions has undefined behavior.
}
\item{
    These functions violate the zero-overhead principle
    by also handling an \tcode{EOF} input,
    and in many use cases, \tcode{EOF} will never be passed into these functions anyway.
    The caller can easily deal with \tcode{EOF} themselves.
}
\item{
    The return type of charater tests is \tcode{int},
    where a nonzero return value indicates that a test succeeded.
    This is very unnatural in C++, where \tcode{bool} is more idiomatic.
}
\item{
    Some functions use the currently installed \tcode{"C"} locale,
    which makes their use questionable for high-performance tasks
    because each invocation is typically an opaque call that checks the current locale.
}
}

\strong{We propose lightweight replacement functions which address all these problems.}

\note{
Many of these problems are resolved by the
\tcode{std::locale} overloads in \header{locale},
but their locale dependence makes them unfit for what this proposal aims to achieve.

Testing whether a \tcode{char8_t} (assumed to be a UTF-8 code unit)
is an ASCII digit is obviously a locale-independent task.
}

\h3{Can't you implement this trivially yourself?}

It is worth noting that some of the functions can be implemented very easily by the user.
For example, existing code may already use a check like \tcode{c >= '0' && c <= '9'}
to test for ASCII digits,
and our proposed \tcode{is_ascii_digit} does just that.

However, not all of the proposed functions are this simple.
For example, checking whether a \tcode{char} is an
ASCII punctuation character (\tcode{'#'}, \tcode{'?'}, etc.)
would require lots of separate checks done naively.
In the standard library, it can be efficiently implemented using a 128-bit or 256-bit bitset.

Even if all proposed functions were trivial to implement,
working with ASCII characters is such an overwhelmingly common use case
that it's worth supporting in the standard library.

\h2{Design}

All proposed functions are \tcode{constexpr},
locale-independent,
overloaded (i.e. no separate name for separate input types),
and accept any character type
(\tcode{char}, \tcode{wchar_t}, \tcode{char8_t}, \tcode{char16_t}, and \tcode{char32_t}).
Furthermore, all function names contain \tt{ascii}
to raise awareness for the fact that these functions do not handle Unicode characters.
A user would expect \tcode{is_upper(U'Ä')} to be \tcode{true},
but \tcode{is_ascii_upper(U'Ä')} to be \tcode{false}.

\example{
The counterpart to \tcode{std::isalpha} is declared follows:
\cppblock{
constexpr bool is_ascii_alpha(\exposid{character-type} c) noexcept;
}
}

\tcode{\ctype} means that there exists an overload set where
this placeholder is replaced with each of the character types.
This design is more consistent with \tcode{std::from_chars} and \header{cmath} functions
than say, \tcode{template<class Char>}.
Equivalent functions could also be added to C, if there is interest.
This signature also allows the use with types that are convertible to a specific character type.

\style{
#fun-table {
    margin-left: auto;
    margin-right: auto;
    max-width: 95%;
    table-layout: auto;
}
#fun-table td:not(:last-child),
#fun-table th {
    white-space: nowrap;
    vertical-align: top;
}
#fun-table td:last-child,
#fun-table th:last-child {
    width: 100%;
    text-align: center;
}
}

\h3{List of proposed functions}

Find below a list of proposed functions.
Note that the character set notation \tt{[}...\tt{]} is taken from RegEx.

\table[id=fun-table]{
\tr{
    \th{\header{cctype}}
    \th{Proposed name}
    \th{Returns (given ASCII \tcode{char c})}
}
\tr{
    \td{\tcode{isdigit}}
    \td{\tcode{is_ascii_digit}}
    \td{\tcode{true} if \tcode{c} is in \charset{0-9}, otherwise \tcode{false}}
}
\tr{
    \td{N/A}
    \td{\tcode{is_ascii_bit}}
    \td{\tcode{c == '0' || c == '1'}}
}
\tr{
    \td{N/A}
    \td{\tcode{is_ascii_octal_digit}}
    \td{\tcode{true} if \tcode{c} is in \charset{0-7}, otherwise \tcode{false}}
}
\tr{
    \td{\tcode{isxdigit}}
    \td{\tcode{is_ascii_hex_digit}}
    \td{\tcode{true} if \tcode{c} is in \charset{0-9A-Fa-f}, otherwise \tcode{false}}
}
\tr{
    \td{\tcode{islower}}
    \td{\tcode{is_ascii_lower}}
    \td{\tcode{true} if \tcode{c} is in \charset{a-z}, otherwise \tcode{false}}
}
\tr{
    \td{\tcode{isupper}}
    \td{\tcode{is_ascii_upper}}
    \td{\tcode{true} if \tcode{c} is in \charset{A-Z}, otherwise \tcode{false}}
}
\tr{
    \td{\tcode{isalpha}}
    \td{\tcode{is_ascii_alpha}}
    \td{\tcode{is_ascii_lower(c) || is_ascii_upper(c)}}
}
\tr{
    \td{\tcode{isalnum}}
    \td{\tcode{is_ascii_alphanumeric}}
    \td{\tcode{is_ascii_alpha(c) || is_asci_digit(c)}}
}
\tr{
    \td{\tcode{ispunct}}
    \td{\tcode{is_ascii_punctuation}}
    \td{\tcode{true} if \tcode{c} is in \charset{!"#\dollar\percent&'()*+,\\-./:;<=>?@\\[\\\\\\]^_`{|}~}, otherwise \tcode{false}}
}
\tr{
    \td{\tcode{isgraph}}
    \td{\tcode{is_ascii_graphical}}
    \td{\tcode{is_ascii_alphanumeric(c) || is_ascii_punctuation(c)}}
}
\tr{
    \td{\tcode{isprint}}
    \td{\tcode{is_ascii_printable}}
    \td{\tcode{is_ascii_graphical(c) || c == ' '}}
}
\tr{
    \td{\tcode{isblank}}
    \td{\tcode{is_ascii_horizontal_whitespace}}
    \td{\tcode{c == ' ' || c == '\\t'}}
}
\tr{
    \td{\tcode{isspace}}
    \td{\tcode{is_ascii_whitespace}}
    \td{\tcode{true} if \tcode{c} is in \charset{ \\f\\n\\r\\t\\v}, otherwise \tcode{false}}
}
\tr{
    \td{\tcode{iscntrl}}
    \td{\tcode{is_ascii_control}}
    \td{\tcode{(c >= 0 && c <= 0x1F) || c == '\\N{DELETE}'}}
}
\tr{
    \td{\tcode{tolower}}
    \td{\tcode{ascii_to_lower}}
    \td{the respective lower-case character if \tcode{is_ascii_upper(c)} is \tcode{true}, otherwise \tcode{c}}
}
\tr{
    \td{\tcode{toupper}}
    \td{\tcode{ascii_to_upper}}
    \td{the respective upper-case character if \tcode{is_ascii_lower(c)} is \tcode{true}, otherwise \tcode{c}}
}
\tr{
    \td{N/A}
    \td{\tcode{ascii_case_insensitive_compare}}
    \td{\i{see \ref[#case-insensitive-comparison]}}
}
\tr{
    \td{N/A}
    \td{\tcode{ascii_case_insensitive_equals}}
    \td{\i{see \ref[#case-insensitive-comparison]}}
}
}

\decision{
The proposed names are mostly unabbreviated
to fit the rest of the standard library style.
Shorter names such as \tcode{is_ascii_alphanum} or \tcode{is_ascii_alnum}
could also be used.
}

\decision{
\tcode{isgraph} should perhaps have no new version.
It is of questionable use,
and both the old and new name aren't obvious.
In the default \tcode{"C"} locale,
\tcode{isgraph} is simply \tcode{isprint} without \tcode{' '}.

Similarly, \tcode{isblank} should perhaps have no new version either.
This proposal simply has a new version for every \header{cctype} function;
if need be, they are easy to remove.
}

\h3[id=base-parameter]{\tcode{base} parameter in \tcode{is_ascii_digit}}

Similar to \tcode{std::to_chars},
\tcode{std::is_ascii_digit} can also take a \tcode{base} parameter:

\cppblock{
constexpr bool is_ascii_digit(\ctype c, int base = 10);
}

If \tcode{base} \c{le} \tcode{10},
the range of valid ASCII digit character is simply limited.
For greater \tcode{base}, a subset of alphabetic characters is also accepted,
starting with \tcode{'a'} or \tcode{'A'}.
Such a function is useful when parsing numbers with a base of choice,
which is what \tcode{std::to_chars} does, for example.

\h3[id=binary-and-octal-is-digit]{\tcode{is_ascii_bit} and \tcode{is_ascii_octal_digit}}

C++ and various other programming languages support binary and octal literals,
so it seems like an arbitrary choice to only have dedicated overloads for (hexa)decimal digits.
\tcode{is_ascii_bit} may be especially useful,
such as when dealing with bit-strings like one of the \tcode{std::bitset} constructors.

In conclusion, we may as well have functions for bases 2, 8, 10, and 16;
they're not doing much harm, they're trivial to implement,
and some users may find them useful.

\note{
None of the authors feel strongly about this,
so if LEWG insists,
we could remove \tcode{is_ascii_bit} and \tcode{is_ascii_octal_digit},
and even remove \tcode{is_ascii_hex_digit},
leaving only the multi-base \tcode{is_ascii_digit}.
}

\h3[id=case-insensitive-comparison]{Case-insensitive comparison functions}

As shown in the table above,
we also propose the case-insensitive comparison functions.

\cppblock{
constexpr strong_ordering ascii_case_insensitive_compare(
    \ctype a,
    \ctype b
) {
    return ascii_to_upper(a) <=> ascii_to_upper(b);
}

constexpr strong_ordering ascii_case_insensitive_equals(
    \ctype a,
    \ctype b
) {
    return ascii_to_upper(a) == ascii_to_upper(b);
}
}

\h3[id=why-no-function-objects]{Why no function objects?}

For case-insensitive comparisons and for character tests in general,
function objects may be convenient because they can be more easily used in algorithms:

\cppblock{
std::string_view str = "abc123";
// This does not work if is_ascii_digit is an overloaded function or function template.
auto it = std::ranges::find(str, is_ascii_digit);
}

However, there is no reason why \tcode{is_ascii_digit} \em{needs} to be a function object.
It is not a customization point, but a plain function.
Furthermore, defining function objects for this purpose may be obsoleted by
\ref[P3312R1] Overload Set Types.

\h3[id=encoding]{What to do for ASCII-incompatible \tcode{char} and \tcode{wchar_t}}

Not every ordinary and wide character encoding is ASCII-compatible,
such as EBCDIC, Shift-JIS, and (defunct) ISO-646,
i.e. code units \c{le} \tcode{0x7f} do not represent the same characters as ASCII.

This begs the question:
what should \tcode{is_ascii_digit('0')} do on an EBCDIC platform,
where this call is \tcode{is_ascii_digit(char(0xf0))} ?
We have three options, discussed below.

\note{
\tcode{is_ascii_digit(u8'0')} is equivalent to \tcode{is_ascii_digit(char8_t(0x30))}
on any platform.
In general, the behavior for Unicode character types is obvious,
unlike that for \tcode{char} and \tcode{wchar_t}.
}

\h4{Conditionally supported \tcode{char} overloads}

We could mandate that the ordinary literal encoding is an ASCII superset
for the \tcode{char} overload to exist.
This would force a cast (to \tcode{char8_t}) to use the functions on EBCDIC platforms.
It is not clear how implementations would treat Shift-JIS;
GCC assumes \tcode{'\\\\' == '¥'} to be \tcode{true},
so this option may not be enough to alleviate
the awkwardness of \tcode{is_ascii_punctuation('¥')}.

Also, this option is not very useful.
It is reasonable to have UTF-8 data stored in a \tcode{char[]} on EBCDIC platforms,
and having to perform casts to \tcode{char8_t} would be awkward.

\h4{Transcode \tcode{char} to ASCII}

We could transcode from the ordinary literal encoding
to ASCII and produce an answer for the result of that transcoding.
This would be a greater burden for implementations,
especially on EBCDIC platforms.
The benefit is that \tcode{is_ascii_digit('0')} is always \tcode{true},
although \tcode{is_ascii_digit(char(0x30))} may not be.
However, \tcode{is_ascii_digit(char8_t(0x30))} is always \tcode{true}.

It probably does not solve the \tcode{is_ascii_punctuation('¥')} case,
as implementers may keep transcoding \tcode{'¥'} and \tcode{'\\\\'} in the same way.
It would also give incorrect answers for stateful encodings.
There are EBCDIC control characters that do not have an ASCII equivalent,
so if we were to do conversions, we would have to decide what,
for example, \tcode{is_ascii_control('\\u008B')} should produce.

\note{
This option was originally preferred by one of the authors,
but proved to be \em{hugely} unpopular in discussion of the proposal.
}

\h4{Treat the input as ASCII, regardless of the literal encoding}

\b{This is our proposed behavior.}

The most simple option is to ignore literal encoding entirely,
and assume that \tcode{char} inputs are ASCII-encoded.
The greatest downside is that depending on encoding,
\tcode{is_ascii_digit('0')} may be \tcode{false},
which may be surprising to the user.
However, the main purpose of these functions is to be called with characters taken from ASCII text,
so what results they yield when passing literals is not so important.

There are use cases for this behavior on EBCDIC platforms.
A lot of protocols (HTTP, POP) and file formats (JSON, XML) are ASCII/UTF-8-based
and need to be supported on EBCDIC systems,
making these functions universally useful,
especially as \header{cctype} functions cannot easily be used to deal with ASCII on these platforms.

Ultimately, do we want functions to deal with ASCII or the literal encoding?
If we want them to be a general way to query the ordinary literal encoding,
\tcode{is_ascii} is a terrible name,
and finding a more general name would prove difficult.

\note{
If we choose this option,
we can still provide the same transcoding functionality as the previous option
by offering a (literal-encoded) \tcode{char} \c{rightarrow} (code point) \tcode{char32_t} function,
although that may be outside the scope of this proposal.
}

\h3{What if the input is a non-ASCII code unit?}

Text input is rarely guaranteed to be pure ASCII,
i.e. some code units may be > \tcode{0x7f}.
However, we're still interested in ASCII characters within that input.
For example, we may
\ul{
\item{parse pure ASCII numbers like \code[json]{123} in a UTF-8 JSON (or other config) file,}
\item{trim ASCII whitespace in HTTP headers, which are encoded with ISO-8859-1,}
\item{
    parse ASCII-alphanumeric variable names in Lua scripts,
    where non-ASCII characters can appear (comments, string),
}
\item{...}
}

It is possible (and expected) that the user calls say,
\tcode{is_ascii_digit(U'ö')}, at least indirectly.
For the sake of convenience, all proposed functions should handle such inputs by
\ul{
    \item{returning \tcode{false} in the case of all testing functions, and}
    \item{applying an identity transformation in transformation/case-insensitive comparison functions.}
}

\example{
With these semantics, the user can safely write:
\cppblock{
std::u8string_view str = u8"öab 123";
// it is an iterator to '1' because 'ö' is skipped
auto it = std::ranges::find(str, [](char8_t c) { return std::is_ascii_digit(c); });
}
If \tcode{is_ascii_digit} doesn't simply return \tcode{false} on non-ASCII inputs,
the proposal is useless for the common use case where some non-ASCII characters exist in the input.
}

The proposed behavior also works excellently with any ASCII-compatible encoding, such as UTF-8.
Surrogate code units in UTF-8 are all greater than \tcode{0x7F},
so if we implement say, \tcode{is_ascii_digit} naively by checking
\tcode{c >= '0' && c <= '9'}, it "just works".

\h3[id=why-not-integers]{Why not accept any integer type?}

Some people argue that a test like \tcode{is_ascii_digit('0')}
is a purely numerical test using the ASCII table,
and so passing \tcode{is_ascii_digit(0x30)} should also be valid.

However, this permissive interface would invite bugs.
For example, \tcode{c - '0'} is the difference between ASCII characters, not an ASCII character,
so passing it into \tcode{is_ascii_digit} would be nonsensical.
Static type systems exist for a reason:
to protect us from stupid mistakes.
While \tcode{char}, \tcode{char32_t} etc. are not required to be ASCII-encoded,
they are at least characters,
so passing them into our functions is likely something the user intended to do,
which we cannot say with confidence about \tcode{int}, \tcode{unsigned int}, etc.

Additionally, if we allowed passing signed integers,
we may want to make the behavior erroneous or undefined for negative inputs
because \tcode{is_ascii_digit(-1'000'000)} is most likely a developer mistake.
Our interface is very simple:
it has a wide contract and almost all functions are \tcode{noexcept}.
Let's keep it that way!

Lastly, even proponents of passing integer types would not want
\tcode{is_ascii_digit(true)} to be valid.

\h3{ASCII case-insensitive views and case transformation algorithms}

Ignoring or transforming ASCII case in algorithms is a fairly common problem.
Therefore, it may be useful to provide views such as \tcode{std::views::ascii_lower},
algorithms like \tcode{std::ranges::equal_ascii_case_insensitive}, etc.

\example{
HTML tag names are case-insensitive and comprised of ASCII characters,
like \code[html]{<div>}, \code[html]{<DIV>} etc.
To identify a \code[html]{<div>} element, it would be nice if the user could write:
\cppblock{
std::ranges::equal(tag_name | std::views::ascii_lower, "div");
// or
std::ranges::ascii_case_insensitive_equal(tag_name, "div");
// or
tag_name.ascii_case_insensitive_equals("div");
}
}

While case transformations can be implemented naively using \tcode{std::transform},
dedicated functions would allow an efficient vectorized implementation for contiguous ranges,
which can be many times faster (\ref[AvoidCharByChar], \ref[AVX-512CaseConv])
Similarly, a case-insensitive comparison function can be vectorized.
In fact, POSIX's \tcode{strncasecmp} has been heavily optimized in glibc (\ref[AVX2strncasecmp]),
and providing range-based interfaces would allow delegating to these heavily optimized functions.

\b{We intend to propose such utilities in a future paper or revision of this paper.}
Currently, this proposal is focused exclusively on operations involving character types.

\h3[id=why-just-ascii]{Why just ASCII?}

It may be tempting to generalize the proposed utilities beyond ASCII, e.g. to UTF-8.
However, this is not proposed for multiple reasons:
\ul{
\item{
    You cannot pass \tcode{char8_t} into a UTF-8 \tcode{is_upper} function
    and expect meaningful results.
    In general, operations on variable-length encodings require sequences of code units.
    The interface we propose \em{only} makes sense for ASCII.
}
\item{
    Unicode utilities are tremendously more complex than ASCII utilities.
    Some Unicode case conversions even require multi-code-point changes.
}
}


\h2{Implementation experience}

A naive implementation of all proposed functions can be found at \ref[CompilerExplorer],
although these are implemented as function templates,
not as overload sets (as proposed).

A more advanced implementation of some functions can be found in \ref[µlight].
Character tests can be optimized using 128-bit or 256-bit bitsets.


\h2{Wording}

The wording changes are relative to \ref[N5008].

In subclause \eelis{version.syn},
update the synopsis as follows:

\diff{\codeblock[cpp,borders=no]{
\serif{\html{[...]}}
#define __cpp_lib_as_const                          201510L // freestanding, also in <utility>
\ins{#define __cpp_lib_ascii                             20XXXXL // freestanding, also in <ascii>}
#define __cpp_lib_associative_heterogeneous_erasure 202110L // also in \serif{[...]}
\serif{\html{[...]}}
}}

In Clause \eelis{text},
append a new subclause:

\style{
ins-block .para::before {
    display: none;
}

.stable-ref {
    float: right;
}
}

\insblock{
\h2[listed=no]{ASCII utilities \stable-ref{ascii}}

Subclause [ascii] describes components for dealing with characters that are encoded using ASCII
or encodings that are ASCII-compatible, such as UTF-8.

\recommended
Implementations should emit a warning when a function in this subclause is invoked
using a value produced by a \grammarterm{string-literal}
or \grammarterm{character-literal} whose encoding is ASCII-incompatible.\br
\wg21-example{
\tcode{is_ascii_digit('0')} is \tcode{false} if the
ordinary literal encoding (\eelis{lex.charset}) is EBCDIC
or some other ASCII-incompatible encoding,
which can be surprising to the user.
However, \tcode{is_ascii_digit(char{0x30})}
is \tcode{true} regardless of ordinary literal encoding.
}

\h3[listed=no]{Header \header{ascii} synopsis \stable-ref{ascii.syn}}

When a function is specified with a type placeholder of
\tcode{\ctype},
the implementation provides overloads for all cv-unqualified 
character types (\eelis{basic.fundamental})
in lieu of \tcode{\ctype}.

\codeblock[cpp,borders=no]{
// \serif{all freestanding}
namespace std {
  // \serif{[ascii.chars.test], ASCII character testing}
  constexpr bool is_ascii_digit(\ctype c, int base = 10);
  constexpr bool is_ascii_bit(\ctype c) noexcept;
  constexpr bool is_ascii_octal_digit(\ctype c) noexcept;
  constexpr bool is_ascii_hex_digit(\ctype c) noexcept;

  constexpr bool is_ascii_lower(\ctype c) noexcept;
  constexpr bool is_ascii_upper(\ctype c) noexcept;
  constexpr bool is_ascii_alpha(\ctype c) noexcept;
  constexpr bool is_ascii_alphanumeric(\ctype c) noexcept;

  constexpr bool is_ascii_punctuation(\ctype c) noexcept;
  constexpr bool is_ascii_graphical(\ctype c) noexcept;
  constexpr bool is_ascii_printable(\ctype c) noexcept;

  constexpr bool is_ascii_horizontal_whitespace(\ctype c) noexcept;
  constexpr bool is_ascii_whitespace(\ctype c) noexcept;

  constexpr bool is_ascii_control(\ctype c) noexcept;

  // \serif{[ascii.chars.transform], ASCII character transformation}
  constexpr \ctype ascii_to_lower(\ctype c) noexcept;
  constexpr \ctype ascii_to_upper(\ctype c) noexcept;

  // \serif{[ascii.chars.case.compare], ASCII case-insensitive character comparison}
  constexpr \ctype ascii_case_insensitive_compare(\ctype a
                                                          \ctype b) noexcept;
  constexpr bool ascii_case_insensitive_equals(\ctype a
                                               \ctype b) noexcept;
}
}

\h3[listed=no]{ASCII character testing \stable-ref{ascii.chars.test}}

\itemdecl{
constexpr bool is_ascii_digit(\ctype c, int base = 10);
}
\itemdescr{
\expects
\tcode{base} has a value between 2 and 36 (inclusive).

\p{
\returns
\codeblock[cpp,borders=no]{\comment   (static_cast<char32_t>(c) >= U'0' && static_cast<char32_t>(c) < U'0' + min(base, 10))
|| (static_cast<char32_t>(c) >= U'a' && static_cast<char32_t>(c) < U'a' + max(base - 10, 0))
|| (static_cast<char32_t>(c) >= U'A' && static_cast<char32_t>(c) < U'A' + max(base - 10, 0))
}
}

\remarks
A function call expression that violates the precondition
in the \expects element
is not a core constant expression.
}

\itemdecl{
constexpr bool is_ascii_bit(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_digit(c, 2)}.
}

\itemdecl{
constexpr bool is_ascii_octal_digit(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_digit(c, 8)}.
}

\itemdecl{
constexpr bool is_ascii_hex_digit(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_digit(c, 16)}.
}

\itemdecl{
constexpr bool is_ascii_lower(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{static_cast<char32_t>(c) >= U'a' && static_cast<char32_t>(c) <= U'z'}.
}

\itemdecl{
constexpr bool is_ascii_upper(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{static_cast<char32_t>(c) >= U'A' && static_cast<char32_t>(c) <= U'Z'}.
}

\itemdecl{
constexpr bool is_ascii_alpha(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_lower(c) || is_ascii_upper(c)}.
}

\itemdecl{
constexpr bool is_ascii_alphanumeric(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_alpha(c) || is_ascii_digit(c)}.
}

\itemdecl{
constexpr bool is_ascii_punctuation(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{u32string_view(U"!\\"#\U{24}\U{25}&'()*+,-./:;<=>?@[\\\\]^_`{|}~").contains(static_cast<char32_t>(c))}.
}

\itemdecl{
constexpr bool is_ascii_graphical(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_alphanumeric(c) || is_ascii_punctuation(c)}.
}

\itemdecl{
constexpr bool is_ascii_printable(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_graphical(c) || static_cast<char32_t>(c) == U' '}.
}

\itemdecl{
constexpr bool is_ascii_horizontal_whitespace(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{static_cast<char32_t>(c) == U' ' || static_cast<char32_t>(c) == U'\\t'}.
}

\itemdecl{
constexpr bool is_ascii_whitespace(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{u32string_view(U" \\f\\n\\r\\t\\v").contains(static_cast<char32_t>(c))}.
}

\itemdecl{
constexpr bool is_ascii_control(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{static_cast<char32_t>(c) <= 0x1F || static_cast<char32_t>(c) == U'\\N{DELETE}'}.
}

\h3[listed=no]{ASCII character transformation \stable-ref{ascii.chars.transform}}

\itemdecl{
constexpr \ctype to_ascii_lower(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_upper(c) ? static_cast<\ctype>(static_cast<char32_t>(c) - U'A' + U'a') : c}.
}

\itemdecl{
constexpr \ctype to_ascii_upper(\ctype c) noexcept;
}
\itemdescr{
\returns
\tcode{is_ascii_lower(c) ? static_cast<\ctype>(static_cast<char32_t>(c) - U'a' + U'A') : c}.
}

\h3[listed=no]{ASCII case-insensitive character comparison \stable-ref{ascii.chars.case.compare}}

\itemdecl{
constexpr std::strong_ordering ascii_case_insensitive_compare(\ctype a,
                                                              \ctype b) noexcept;
}
\itemdescr{
\returns
\tcode{ascii_to_upper(a) <=> ascii_to_upper(b)}.
}

\itemdecl{
constexpr bool ascii_case_insensitive_equals(\ctype a,
                                             \ctype b) noexcept;
}
\itemdescr{
\returns
\tcode{ascii_to_upper(a) == ascii_to_upper(b)}.
}

}

\note{
Some uses of \tcode{static_cast} are unnecessary to describe semantics.
For example, \tcode{static_cast<char32_t>(c) == U' '}
is equivalent to \tcode{c == U' '}.

However, these uses of \tcode{static_cast} may improve readability and avoid
the use of behavior which we intend to deprecate.
For example, we will soon publish a paper which seeks to deprecate
implicit conversions between \tcode{char8_t} and \tcode{char32_t}.
}


\h2{References}

\bib[
    id = N5008,
    title = Working Draft\, Programming Languages — C++,
    date = 2025-03-15,
    author = Thomas Köppe,
    link = https://wg21.link/n5008,
    long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/n5008.pdf
]
\bib[
    id = P3312R1,
    title = Overload Set Types,
    date = 2025-04-16,
    author = Bengt Gustafsson,
    link = https://wg21.link/p3312r1,
    long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/p3312r1.pdf
]
\bib[
    id = CompilerExplorer,
    title = Partial implementation of character utilities,
    author = Jan Schultke\, Corentin Jabot,
    link = https://godbolt.org/z/5nvWzdf8G
]
\bib[
    id = µlight,
    title = ascii_chars.hpp utilities in µlight,
    author = Jan Schultke,
    link = https://github.com/Eisenwave/ulight/blob/main/include/ulight/impl/ascii_chars.hpp
]
\bib[
    id = AVX2strncasecmp,
    title = glibc [PATCH v1 21/23] x86: Add AVX2 optimized str{n}casecmp,
    date = 2022-03-23,
    author = Noah Goldstein,
    link = https://sourceware.org/pipermail/libc-alpha/2022-March/137272.html
]
\bib[
    id = AvoidCharByChar,
    title = Avoid character-by-character processing when performance matters,
    date = 2020-07-21,
    author = Daniel Lemire,
    link = https://lemire.me/blog/2020/07/21/avoid-character-by-character-processing-when-performance-matters/
]
\bib[
    id = AVX-512CaseConv,
    title = Converting ASCII strings to lower case at crazy speeds with AVX-512,
    date = 2024-08-03,
    author = Daniel Lemire,
    link = https://lemire.me/blog/2024/08/03/converting-ascii-strings-to-lower-case-at-crazy-speeds-with-avx-512/
]

\make-bib
