<pre class='metadata'>
Title: Bit-permutation for `<bit>`
Shortname: Pxxxx
Revision: 0
Status: NP
Date: 2024-01-16
Group: WG21
Audience: LEWGI, LEWG
Editor: Jan Schultke, janschultke@gmail.com
!Source: [eisenwave/cpp-proposals](https://github.com/Eisenwave/cpp-proposals/blob/master/src/enum-direct-init.bs)
Markup Shorthands: markdown on
Abstract: This proposal adds functions two the `<bit>` header which abstract the
          PDEP and PEXT x86 instructions.
</pre>

Introduction {#intro}
=====================

This proposal seeks to expand the `<bit>` header with the following bit-permutation functions:
```cpp
template<class T>
constexpr T compress_bits(T x, T mask) noexcept;
```
For each one-bit in `mask`, the corresponding bit in `x` is taken and packed
contiguously into the result.
This operation is directly implemented in x86_64 BMI2 through
[PEXT (Parallel Bits Extract)](https://www.felixcloutier.com/x86/pext).

```cpp
template<class T>
constexpr T expand_bits(T x, T mask) noexcept;
```
For each one-bit in mask, a bit from `x` is taken and shifted into the corresponding position of the
mask bit.
This operation is directly implemented in x86_64 BMI2 through
[PDEP (Parallel Bits Deposit)](https://www.felixcloutier.com/x86/pdep)


Motivation and scope {#motivation-and-scope}
============================================

Compression and expansion are fundamental operations that meet multiple criteria which make
them suitable for standardization:

They serve as building blocks for more complex operations. {#building-blocks}
---
A common use case for PDEP is interleaving bits.
`expandr_bits(x, 0b...101010) | expandr_bits(y, 0b...010101)` can be used to interleave the
bits of two numbers `x` and `y`.
This translates Cartesian coordinates to the index on a
[Z-order curve](https://en.wikipedia.org/wiki/Z-order_curve).
Space filling curves are a popular technique in compression.

The operations can also be used in various I/O-related applications.
The operation `(x >> 4) & 0b11`, which extracts the 5th and 6th least significant bits can also be
expressed as `compress_bits(x, 0b110000)`.
Compression also handles gaps between bits.

A GitHub code search for
`/(_pdep_u|_pext_u)(8|16|32|64)/ AND language:c++`
reveals ~1300 files which use the intrinsic wrappers for the x86 instructions.
To name some examples, the intrinsic is used in Base-64 and UTF-8 encoding/decoding,
as well as bitboard chess engines. 

They benefit greatly from hardware support. {#hardware-support}
---
Starting with Haswell, Intel CPUs directly implement compression and expansion with
with
[PDEP (Parallel Bits Deposit)](https://www.felixcloutier.com/x86/pdep) and
[PEXT (Parallel Bits Extract)](https://www.felixcloutier.com/x86/pext).
Intel x86_64 CPUs, as well AMD CPUs starting with Zen 3 implement PDEP and PEXT with 3 cycles
latency.
Zen 2 and older implement PDEP/PEXT in microcode, with 18 cycles latency.

There is no other instruction set with a direct equivalent.
However, when the mask is a constant, many different strategies for hardware-acceleration open up.
For example
- interleaving bits can be assisted (though not fully implemented) using ARM `ZIP1`/`ZIP2`
- other permutations can be assisted by ARM `TBL` and `TBX`


For known mask values, implementation strategies change greatly {#implementation-strategies}
---
On architectures where there is no direct hardware support such as `PDEP`,
or where `PDEP` and `PEXT` are costly,
the implementation strategy for these operations depends greatly on the following information:

1. Is the mask sparsely populated?
    - If so, consider an algorithm which traverses each mask bit.
2. Is the mask a single bit, or a single group of consecutive bits?
    - If so, the operation can be implemented in terms of a single shift and bitwise AND.
3. Does the mask have relatively few gaps?
    - If so, multiple shifts and bitwise ANDs may be needed, but are likely still optimal up to a
         certain amount of groups.
4. Is the amount of gaps in the mask known, even if the exact mask isn't known?
    - This could make the latter strategy highly preferrable, with full loop unrolling.
5. Are all gaps in the mask equally spaced?
    - If so, the operation boils down to interleaving or removing equally spaced bits,
         and there exists a simple solution with logarithmic complexity.

Some of these special cases may be worth detecting using traditional branching.
Some of these special cases are only worth detecting for known constant masks, or masks which
become known during optimization passes.
The choice of strategy is also impacted by other available hardware support, such as for
`std::countr_zero`.

All in all, there are two factors that suggest a standard library implementation:
1. The strategy for computing `compress_bits` and `expand_bits` depends greatly on the architecture
    and on information about the mask, even if the exact mask isn't known.
2. ISO C++ does not offer a mechanism by which all of this information can be utilized.
    Namely, it is not possible to decide based on information that only becomes available during
    optimization passes.
    Compiler extensions such as `__builtin_constant_p` offer a workaround.


Impact on existing code {#impact-on-existing-code}
==================================================

This proposal is purely a standard library expansion.
No existing code is affected.



Design considerations {#design}
===============================

Why the names `compress_bits` and `expand_bits`? {#naming}
---
When talking about the proposed operations, there are typically two sets of terminology:
1. `deposit`/`extract`
2. `compress`/`expand`

The latter is preferrable because the former terminology is rather ambiguous:

Taking the input `0b10101` and densely packing it to `0b111` could be described as:
> Extract each second bit from `0b10101` and densely deposit it into the result.

Similarly, taking the input `0b111` and expanding it into `0b10101` could be described as:
> Extract each bit from `0b111` and sparsely deposit it in the result.

Both operations can be described with `extract` and `expand` terminology,
making it virtually useless in keeping the operations apart.


Should there be more general functions? {#more-general}
---
[[N3864]] originally suggested much more general versions, which includes:
1. compressing/expanding not just low-order bits, but also high-order bits
2. performing the operation not just on the whole operand, but on "words" of it
3. performing the operation not just on bits, but on arbitrarily sized groups of bits

**I don't propose this generality** for the following reasons:
1. The utility functions in `<bit>` are not meant to provide a full bitwise manipulation library,
    but fundamental operations, especially those that can be accelerated
    in hardware while still having reasonable software fallbacks.
2. These more general form can be built on top of the proposed hardware-oriented versions.
    This can be done with relative ease and with little to no overhead.
3. The generality falsely suggests hardware support for all forms, despite the function only being
    accelerated for specific inputs.
    This makes the performance characteristics unpredictable.
4. The proposed functions have wide contracts and can be `noexcept` (Lakos rule).
    Adding additional parameters would likely require a narrow contract.
5. Generality adds complexity to the standardization process, to implementation,
    and from the perspective of language users.
    It is unclear whether this added complexity is worth it in this case.


Possibe implementation {#possible-implementation}
======================================================

The following implementation is very naive, but compliant:
```cpp
template<class T>
  requires is_unsigned_v<T>
constexpr T compress_bits(T x, T mask) noexcept
{
    T result = 0;
    for (T i = 0, j = 0; i != numeric_limits<T>::digits; ++i) {
        if ((mask >> i) & 1) {
            result |= ((x >> i) & 1) << j++;
        }
    }
    return result;
}

template<class T>
  requires is_unsigned_v<T>
constexpr T expand_bits(T x, T mask) noexcept
{
    T result = 0;
    for (T i = 0, j = 0; i != numeric_limits<T>::digits; ++i) {
        if ((mask >> i) & 1) {
            result |= ((x >> j++) & 1) << i;
        }
    }
    return result;
}
```
[[Warren1]] presents much less naive and likely much faster software implementations.

Proposed wording {#proposed-wording}
====================================

Let `x` be a sequence of binary digits x<sub>i</sub>
where `x` = Sum(*x*<sub>*i*</sub> 2<sup>*i*</sup>) for 0 &le; *i* &lt; N.<br>
Let `m` be a sequence of binary digits m<sub>i</sub>
where `m` = Sum(*m*<sub>*i*</sub> 2<sup>*i*</sup>) for 0 &le; *i* &lt; N.

Let *p*(i) = Sum(*m*<sub>*k*</sub>) for 0 &le; *k* &lt; i. 

Note: *p*(*i*) can be computed with `popcount(m & ~(T(-1) << i))`.

`expand_bits(x, m)` returns
Sum(*m*<sub>i</sub> *x*<sub>*p*(*i*)</sub> 2<sup>*i*</sup>) for 0 &le; *i* &lt; N.

`compress_bits(x, m)` returns
Sum(*m*<sub>i</sub> *x*<sub>*i*</sub> 2<sup>*p*(*i*)</sup>) for 0 &le; *i* &lt; N.

The proposed changes are relative to the working draft of the standard as of [[!N4917]].

Insert a new bullet in 9.4.1 [dcl.init.general] paragraph 16, between bullets 7 and 8:

<blockquote>
<ins>
Otherwise, if<ul>
<li>the destination type `T` is an enumeration with a fixed underlying type ([dcl.enum]) `U`,</li>
<li>the parenthesized *expression-list* of the *initializer* has a single element `v` of scalar type, and</li>
<li>`v` can be implicitly converted to `U`,</li>
</ul>
the object is initialized with the value `static_cast<T>(v)` ([expr.type.conv]).
</ins>
</blockquote>

Note: This bullet covers all forms of direct-initialization except list-initialization
      and `static_cast`.
      List-initialization is already covered by an earlier bullet, and `static_cast` has no
      *expression-list*, only a single *expression*.

Modify 9.4.5 [dcl.init.list] paragraph 3 bullet 8 as follows:

<blockquote>
<del>
Otherwise, if `T` is an enumeration with a fixed underlying type ([dcl.enum]) `U`,
the *initializer-list* has a single element `v` of scalar type,
`v` can be implicitly converted to `U`, and
the initialization is direct-list-initialization,
</del>
<br>
<ins>
Otherwise, if<ul>
<li>`T` is an enumeration with a fixed underlying type ([dcl.enum]) `U`,</li>
<li>the *initializer-list* has a single element `v` of scalar type,</li>
<li>`v` can be implicitly converted to `U`, and</li>
<li>the initialization is direct-list-initialization,</li>
</ul>
</ins>
the object is initialized with the value
<del>`T(v)` ([expr.type.conv])</del><ins>`static_cast<T>(v)` ([expr.static.cast])</ins>;
if a narrowing conversion is required to convert `v` to `U`, the program is ill-formed.
</ins>
</blockquote>

Note: This change is strictly editorial.
      It would be valid to keep list-initialization defined in terms of `T(v)` instead
      of `static_cast<T>(v)`.
      However, the semantics of `T(v)` in [expr.type.conv] are delegated to `static_cast`
      in [expr.static.cast] anyway, which is an unecessary double indirection.


<pre class=biblio>
{
    "P0960R3": {
        "authors": ["Ville Voutilainen", "Thomas KÃ¶ppe"],
        "href": "https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0960r3.html",
        "title": "Allow initializing aggregates from a parenthesized list of values",
        "publisher": "WG21"
    },
    "P0138R2": {
        "authors": ["Gabriel Dos Reis", "Microsoft"],
        "href": "https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0138r2.pdf",
        "title": "Construction Rules for enum class Values",
        "publisher": "WG21"
    },
    "Warren1": {
        "authors": ["Henry S. Warren, Jr."],
        "title": "Hacker's Delight, 2nd Edition",
        "publisher": "Addision-Wesley",
        "type": "Book",
        "chapter": "7-4, 7-5"
    },
    "N3864": {
        "authors": ["Matthew Fioravante"],
        "href": "https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3864.html",
        "title": "A constexpr bitwise operations library for C++",
        "publisher": "WG21"
    },
    "P0553R4": {
        "authors": ["Jens Maurer"],
        "href": "https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0553r4.html",
        "title": "Bit operations",
        "publisher": "WG21"
    }
}
</pre>