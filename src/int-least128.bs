<pre class='metadata'>
Title: <code>std::int_least128_t</code>
Shortname: Pxxxx
Revision: 0
Status: NP
Date: 2024-02-05
Group: WG21
Audience: LEWGI, LWG
Editor: Jan Schultke, janschultke@gmail.com
ED: https://eisenwave.github.io/cpp-proposals/int-least128.html
!Source: [eisenwave/cpp-proposals](https://github.com/Eisenwave/cpp-proposals/blob/master/src/int-least128.bs)
Markup Shorthands: markdown on
Abstract: This proposal standardizes 128-bit integers.
</pre>


# Introduction # {#introduction}

128-bit integers have countless practical uses, and all major implementations
(MSVC, GCC, LLVM) expose 128-bit integers as a language extension already.
There has been great interest in standardizing integers beyond 64 bits for a long time,
and with the new wording in the C standard for `intmax_t` (see [[#c-compatibility]]),
one of the last obstacles has been removed.

The goal of this paper is to obtain a mandatory &ge; 128-bit integer type with no core language changes
and strong support from the C++ standard library.
To accomplish this, the mandatory aliases `std::int_least128_t` and `std::uint_least128_t`
are proposed.

Note: The implementation optionally provides `std::int128_t` and `std::uint128_t` aliases.

While the definition of these aliases is trivial, mandating them also implies
library support from `<format>`, `<bit>`, `<cmath>`, `<limits>`, and other facilities.
Such library support is crucial for a fully-fledged and useful 128-bit type.
[[#library-impact]] demonstrates that the impact on the standard is not overwhelming,
and [[#implementation-impact]] summarizes the impact on implementations,
which is equally manageable.

# Motivation and scope # {#motivation-and-scope}

There are two essential reasons for standardizing a 128-bit integer type:

1. 128-bit integers are extremely useful in a variety of domains.

2. 128-bit integers are already implemented in multiple compilers, and quasi-mandated by the C23
    standard through the `_BitInt(128)` and `unsigned _BitInt(128)` types.
    That is, if the implementation defines `BITINT_MAXWIDTH >= 128`.
    See [[#existing-128-bit-integers]] for more.

## Use cases ## {#use-cases}

To motivate this proposal, I will briefly introduce a few use cases of 128-bit integers.

### Cryptography ### {#cryptography}

128-bit integers are commonly used in many cryptographic algorithms:

- Most notably, AES-128 uses a 128-bit key size.
    AES variants with wider key sizes still use a block size of 128 bits.
- Various other block ciphers such as Twofish and Serpent also have key and/or block sizes of 128 bits.
- MD5 hashes produce 128-bit output.
- SHA-2 and SHA-3 produce outputs beyond 128-bit, but outputs can be truncated to 128-bit,
    or represented as a pair/array of 128-bit integers.

### Random number generation ### {#random-number-generation}

Some random number generators produce 128-bit numbers.

For example, the CSRPNG (cryptographically secure pseudo-random number generator)
Fortuna uses a block cipher to produce random numbers.
When a 128-bit block cipher is used, the output is naturally 128-bit as well.
Fortuna is used in the implementation of `/dev/random` in FreeBSD 11, and in AppleOSes since 2020.

### Widening operations ### {#widening-operations}

[[P3018R0]] proposed widening operations which yield an integer with double the width of the input.
An obvious issue is that the language provides no 128-bit integer type, so the widening
operations for 64-bit operands could not exist, or would return a type which is not
considered an integer.

Note: Extended integer types require extensive library support, so the implementation couldn't
      simply return an extended 128-bit integer type without sufficiently supporting such at type.

This obstacle is especially unfortunate considering that hardware often supports 64-to-128-bit
widening operations directly.
For example:

- The x86_64 `mul` (unsigned multiply) instruction stores the result of a 64-to-128-bit multiplication
    in the register pair `rdx:rax`.
- The x86_64 `div` (unsigned divide) instruction stores quotient and remainder of a 128-to-64-bit division
    in `rax` and `rdx` respectively.
- RISC-V provides the `clmul` and `clmulh` instructions to compute the low and high part of a
    carry-less multiplication.
    In fact, x86, ARM, and RISC-V all provide a way to compute a carry-less 128-bit product. 

Some operating systems also provide 128-bit operations.
For example, the Windows API provides a `Multiply128` function.

### Multi-precision operations ### {#multi-precision-operations}

For various applications (cryptography, various numeric applications, etc.) arithmetic with
large bit sizes is required.
For example, the RSA (Rivest–Shamir–Adleman) cryptosystem typically uses bit sizes of 2048 or 4096.

This involves addition, multiplication, and division with multi-precision integers, which is
implemented digit-by-digit.
For example, to implement multiplication,
the number can be split into 32-bit or 64-bit digits, and long multiplication can be performed,
where the high part of the multiplication could be obtained from the high 64-bits of a 128-bit
result.

Note: Such a widened 128-bit result could be obtained through [[#widening-operations]] operations.

### Double-wide atomic operations ### {#double-wide-atomic-operations}

Some architectures provide double-wide atomic operations.
For example, x86_64 provides a `cmpxchg16b` instruction which can be used to implement a
128-bit `std::atomic::compare_exchange_strong`.

Such an operation is useful for lock-free data structures, where a simple CAS is often insufficient
because two 64-bit pointers or a 64-bit pointer with some metadata have to be compared and swapped
simultaneously.

To be fair, this operation is already exposed through `std::atomic<std::array<std::byte, 16>>`,
so 128-bit atomic integers aren't strictly necessary except for 128-bit `.fetch_xxx` operations,
though those don't have direct hardware support.

### High-precision clocks ### {#high-precision-clocks}

64-bit integers are somewhat insufficient for high-precision clocks, if large time spans should
also be covered.
When counting nanoseconds, a maximum value of 2<sup>63</sup>-1 can only represent approximately
9 billion seconds, or 7020 years.

This makes 64-bit integers insufficient for some time calculations, where 128-bit integers
would suffice.
Alternatively, 64-bit floating-point numbers can provide a reasonable trade-off.

### Floating-point operations ### {#floating-point-operations}

The implementation of IEEE 754/IEC-559 floating-point operations often involves examining the
bit-representation of the floating-point number through an unsigned integer.

The C++ standard provides `std::float128_t`, but no matching 128-bit integer type,
which makes this more difficult.

<div class="example">
Using 128-bit integers, `std::signbit` can be implemented as follows:

```cpp
bool signbit(float128_t x) {
    return bit_cast<uint128_t>(x) >> 127;
}
```
</div>

### Financial systems ### {#financial-systems}

128-bit integers can be used to represent huge monetary values.
For example, the smallest fraction of a Bitcoin is a Satoshi, where one Bitcoin equals
a million Satoshis.
A signed 64-bit integer can only losslessly represent approximately 10<sup>13</sup> Bitcoins.

### Database systems ### {#database-systems}

A 128-bit integer can be used to represent a UUID (Universally Unique Identifier).
While 64-bit integers are often sufficient as a unique identifier, it is quite likely that two
identical identifiers are chosen by a random number generator over a long period of time,
especially considering the Birthday Paradox.
Therefore, at least 128 bits are typically used for such applications.

### Networking ### {#networking}

IPv6 addresses can be represented as a 128-bit integer.
This may be a convenient representation because bitwise operations for masking and accessing
individual bits or bit groups may be used, and implementing these is much easier using a 128-bit
integer compared to multi-precision operations using two 64-bit integers.


# Impact on the standard # {#impact-on-the-standard}

First and foremost, this proposal mandates the following integer types in `<cstdint>`:
```cpp
using int_least128_t  = /* signed integer type */;
using uint_least128_t = /* unsigned integer type */;

using int_fast128_t   = /* signed integer type */;
using uint_fast128_t  = /* unsigned integer type */;

using int128_t = /* signed integer type */; // optional
using uint128_t = /* unsigned integer type */; // optional

// The corresponding macros for MIN and MAX must also be defined ...
```
This change in itself is almost no change at all.
The implementation can already provide `int_least128_t` while complying with the C++11 standard.
However, this change has far-reaching ramifications which are examined below.

## C Compatibility ## {#c-compatibility}

Any attempt of standardizing 128-bit integers must also keep possible compatibility with the C
standard in mind.
C does not guarantee a `int_least128_t` alias, but `intmax_t` may present a potential point of
conflict.

[[N3047]], 7.22.1.5 [Greatest-width integer types] currently defines `intmax_t` as follows:

<blockquote>
The following type designates a signed integer type, other than a bit-precise integer type, capable of
representing any value of any signed integer type with the possible exceptions of signed bit-precise
integer types and of signed extended integer types that are wider than `long long` and that are
referred by the type definition for an exact width integer type:
```cpp
intmax_t
```
</blockquote>

For `intmax_t` to not be `int_least128_t` in the C standard, there must exist an `int128_t`
alias for the same type.
GCC already provides an `__int128` type which satisfies the padding-free requirement and could
be exposed as `int128_t`.

In conclusion, it is possible to mandate a `std::int_least128_t` alias without sacrificing
C-compatibility.


## Impact on the core language ## {#core-impact}

The proposal makes no changes to the core language.
However, it is worth noting that the existence of `std::uint_least128_t` leads to some oddities:

- The result of the `sizeof` operator can be a 128-bit integer.
- The underlying type of enumerations can be a 128-bit integer.
- Previously ill-formed integer literals could now be of 128-bit integer type.
- The conditions in `#if` preprocessing directives are evaluated as if operands had the same
    representation as `intmax_t` or `uintmax_t`,
    which means that 128-bit integers cannot be used in this context, or the values
    would be truncated.

However, none of this is a new issue introduced by this proposal.
Any compliant implementation could already have produced this behavior,
assuming it supported 128-bit integers as an optional extended integer type.

While there is certainly software which relies on `std::size_t` and other types not exceeding
64 bits, not defining `std::size_t` to be a 128-bit type is a QoI (Qualify of Implementation) issue.
Such problems are not within the scope of the standard, and I don't see it as necessary
to add Recommended Practice paragraphs as protection against malicious implementations.


## Impact on the library ## {#library-impact}

To properly integrate 128-bit integers into the standard, it is also necessary to provide
library support.
What use is a standard 128-bit integer if it cannot be turned into a string or used in any of the
standard library math functions?

Find below a summary of issues that arise from the introduction of 128-bit integers in the
C++ standard library.
One common issue is that aliases such as `size_type` and `difference_type` within
containers, iterators, and other types can be a 128-bit integer.
Whether to define them as such is a QoI issue in general, and won't be discussed further.

### Language support library ### {#library-impact-language-support}

**Issue:** Certain type aliases such as `ptrdiff_t` and `size_t` could now be defined as a 128-bit type.<br>
**Action:** ✔️ No impact on the standard.
Whether to do so is a QoI issue.

**Issue:** `std::to_integer` would need 128-bit support.<br>
**Action:** ✔️ No impact on the standard.

Note: An implementation is trivial.
      `std::to_integer` is equivalent to a single `static_cast`.

**Issue:** `<version>` would likely need a 128-bit integer feature-testing macro.<br>
**Action:** ⚠️ Add a macro.

**Issue:** `<numeric_limits>` would need a trait for 128-bit integers.<br>
**Action:** ✔️ No impact on the standard; require a `std::numeric_limits` specialization.

Note: GCC already provides `std::numeric_limits<__int128>` as an extension.

**Issue:** `<climits>` would need additional constants for 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

**Issue:** `<cstdint>` would need need to explicitly require support for 128-bit integers
in its synopsys.<br>
**Action:** ⚠️ Define aliases such as `int_least128_t` and explicitly state that 128 bits are supported.

### Metaprogramming library ### {#library-impact-metaprogramming}

**Issue:** `std::is_integral` needs to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: GCC already implements `std::is_integral<__int128>`.
Implementing this trait is not difficult in general.

**Issue:** `std::rank<T>::value` could be a 128-bit integer.<br>
**Action:** ✔️ No impact on the standard.

Note: This depends on whether `std::size_t` is a 128-bit integer, and this decision is QoI.

**Issue:** `std::make_signed` and `std::make_unsigned` require 128-bit support.<br>
**Action:** ✔️ No impact on the standard.
GCC already implements `std::make_{un}signed<__int128>`.

**Issue:** `std::ratio` currently accepts non-type template arguments of `std::intmax_t`.
`std::intmax_t` is no longer the widest integer type and changing the type of NTTP to
`std::uint_least128_t` would be an ABI break because the type of template argument participates
in name mangling.<br>
**Action:** ✔️ No impact on the standard.

Note: Unfortunately ratios beyond 2<sup>64</sup> or 2<sup>-64</sup>
cannot be represented, assuming that `std::intmax_t` is a 64-bit integer.

### General utilities library ### {#library-impact-utilities}

**Issue:** Integer comparison functions (`std::cmp_equal` et al.) require 128-bit support.
**Action:** ✔️ No impact on the standard.
Existing implementations are generic and could support 128-bit integers with no changes.

**Issue:** `std::integer_sequence` would need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: The implementation of `std::integer_sequence` or `std::make_integer_sequence` does not depend
on a specific integer width.

**Issue:** `std::bitset` could receive an additional constructor taking `std::uint_least128_t`.<br>
**Action:** ⚠️ Add such a constructor.

**Issue:** `std::bitset` could receive an additional `to_u128` function, similar to `to_ullong`.<br>
**Action:** ⚠️ Add such a function.

**Issue:** `std::to_chars` and `std::from_chars` would need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: 128-bit stringification can be implemented in terms of one to three 64-bit stringifications
      and integer divisions with constant divisor.
      In the special case where the base of conversion is a power of two, no integer division is
      needed, and a 64-bit implementation can be repurposed.

**Issue:** `<format>` facilities need to support 128-bit integers.<br>
**Action:** ⚠️ To be investigated.

Note: The locale-independent forms are simply implemented in terms of `std::to_chars` and are not
affected.
However, it needs to be clear whether locale support for 128-bit integers would constitute
an ABI break.

**Issue:** `basic_format_parse_context::check_dynamic_spec` and `basic_format_parse_context::check_dynamic_spec_integral` could possibly support 128-bit integers.<br>
**Action:** ⚠️ Add support for 128-bit integers.
This is not an ABI break.

**Issue:** `basic_format_arg` may need direct support for 128-bit integers rather than using the
fallback case of initializing a value with `handle(v)`.<br>
**Action:** ⚠️ To be investigated.

**Issue:** Bit manipulation functions in `<bit>` need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: For most functions, a 128-bit implementation simply combines the results of calling the 64-bit
variant for the low and high bits.
For example, `popcount(std::uint128_t x)` returns
`popcount<std::uint64_t>(x >> 64) + popcount<std::uint64_t>(x)`.

**Issue:** It would be convenient if `std::to_string` support 128-bit types.<br>
**Action:** ⚠️ Support should be provided.
However, this issue is dealt with in [[Schultke1]], not in this proposal.

### Containers library ### {#library-impact-containers}

**Issue:** The extents and index types of `std::mdspan` could be 128-bit integers.
This is also the case for type aliases of `std::strided_slice`.
The exposition-only helper <code><i>integral-constant-like</i></code> now also includes
128-bit integers.<br>
**Action:** ✔️ No impact on the standard.
All these issues are either QoI or don't impact existing implementations substantially.

### Iterators library ### {#library-impact-iterators}

**Issue:** The exposition-only helper <code><i>integral-constant-like</i></code> now also includes
128-bit integers.
Generally, 128-bit integers would be a valid `difference_type` and an implementation needs to
consider this when defining concepts that use integers in any way.<br>
**Action:** ✔️ No impact on the standard.

Note: As long as `std::is_integral` (and by proxy, `std::integral`) is correct, the existing wording
should be unaffected.


### Ranges library ### {#library-impact-ranges}

**Issue:** `std::iota_view<W>::iterator::difference_type` where `W` is an integral type is defined to be
a wider integer type if such a type exists, and `iter_difference_t<W>` is not wider.
This causes an issue for existing implementations that don't consider 128-bit integers to exist,
and for `W = std::uint_least128_t`, this may necessitate a &ge; 129-bit integer.
Similarly, `std::repeat_view::iterator::difference_type` is affected.<br>
**Action:** ⚠️ To be investigated.

**Issue:** `std::cartesian_product_view::size` may now return a 128-bit integer.
The standard recommends to use a type which is sufficiently wide to store the product
of sizes of underlying ranges.
A similar issue arises for `std::cartesian_product_view::iterator`.<br>
**Action:** ✔️ No impact on the standard.

Note: The choice of integer type used to be (and still is) implementation-defined.


### Algorithms library ### {#library-impact-algorithms}

**Issue:** `std::gcd`, `std::lcm`, and `std::midpoint` need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: For GCD computation, algorithms which don't rely on integer division exist, such as Binary GCD.
Therefore, a reasonably fast 128-bit version is possible.
`std::midpoint` can be implemented in a width-agnostic way.

**Issue:** Saturating arithmetic functions and `saturate_cast` need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: Existing 64-bit implementations that don't rely on 128-bit types can be equally used for 128-bit
types.

### Numerics library ### {#library-impact-numerics}

**Issue:** Various random number generators and `std::uniform_int_distribution` need to support
128-bit types.<br>
**Action:** ✔️ No impact on the standard.

Note: The implementation of random number generators does not usually rely on bit widths being lower
than 128-bit.
Some generators such as linear congruential engines rely heavily on modulo division,
which is very expensive for 128-bit integers.
However, this can be simplified to fixed-point multiplication and bit-shifting for a known modulo,
which is always the case in generators, though not in distributions.

**Issue:** `std::seed_seq` needs to support `std::initializer_list<std::uint128_t>`.<br>
**Action:** ✔️ No impact on the standard.

Note: This can be implemented by splitting each 128-bit integer into two 64-bit integers and
repurposing and existing implementation.

**Issue:** `std::valarray` needs to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: `std::valarray` does not rely on using integer types specifically.
Treating 128-bit integers specially and utilizing hardware resources is a QoI issue.

**Issue:** For most `<cmath>` functions, an additional overload taking 128-bit integers would
need to be defined.<br>
**Action:** ✔️ No impact on the standard.

Note: The overload taking `std::uint_least128_t` would convert to `double`, like other functions.
`double` is more than enough to represent the maximum 128-bit integer value, however,
it should be considered whether `long double` should be used to minimize loss of precision.

**Issue:** `std::abs` should receive an additional 128-bit overload.<br>
**Action:** ⚠️ Add an overload `std::uint_least128_t abs(std::uint_least128_t)`.

Note: Without such an overload, `std::uint_least128_t` would delegate to `abs(double)`.

**Issue:** The `<linalg>` library may need 128-bit support.<br>
**Action:** ✔️ No impact on the standard.

Note: The linear algebra library operates on `std::mdspan` of any type.
Treating 128-bit integers specially and utilizing hardware resources is a QoI issue.

### Time library ### {#library-impact-time}

**Issue:** Significant portions of `<chrono>` use `std::ratio`, which has `std::intmax_t` template
parameters.<br>
**Action:** ✔️ No impact on the standard.

<div class="note">
<span class="marker">Note:</span>
`std::ratio` cannot represent certain extreme ratios
if `std::intmax_t` is narrower than `std::uint_least128_t`.
However, the time library is generally safe to use, even if the representation of say,
`std::duration` is wider than the types used in a `std::ratio` fraction.
      
If there is future interest, types such as `std::duration`
could be relaxed to work with *ratio-like* types,
so that a new 128-bit `std::ratio`-style type could be used as well,
not just `std::ratio` itself.
However, this is a significant extension of the time library and not part of this proposal.
</div>

### Localization library ### {#library-impact-localization}

**Issue:** `std::num_get` and `std::num_put` could use `std::uint_least128_t` overloads for `do_get`.<br>
**Action:** ✔️ No impact on the standard.

Note: This would be a an ABI break if changes were made.
`std::format` and `std::print` provide sufficient alternatives which can be supported without
breaking ABI.

### Input/output library ### {#library-impact-io}

**Issue:** `std::num_get` and `std::num_put` don't support 128-bit integers.
By proxy, extraction and insertion with `operator>>` would not work.<br>
**Action:** ✔️ No impact on the standard.

Note: The standard doesn't require these to work for all integer types, only for standard integer types.
Any change would be an ABI break, so these facilities could be left untouched.
Unfortunately, the user won't be able to `std::cout << std::uint_least128_t{...}`, however,
the language provides sufficient alternatives.

**Issue:** `std::printf` and `std::scanf` need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: If `std::to_chars` and `std::format` are already mandated, it is reasonable to expect `std::printf`
support as well.
`PRIoLEAST128` would also need to be defined, but this has no impact on the existing wording.


### Concurrency support library ### {#concurrency-support-library}

**Issue:** `std::atomic` needs to support `std::uint_least128_t`.<br>
**Action:** ✔️ No impact on the standard.

Note: `std::atomic` specializations are already defined for all integer types.
On x86_64, all `.fetch` operations would fall back onto CAS-and-retry loops
utilizing the `cmpxchg16b` instruction.
This would be no better than using a `std::atomic<std::array<std::byte, 16>>`.
However, these are generally QoI issues and there is no restriction that would prevent
`std::atomic<std::int_least128_t>` specializations, even if hardware support is very limited.

**Issue:** There should be additional aliases `std::atomic_uint_least128_t` et al. aliases.<br>
**Action:** ⚠️ Define aliases following the same convention as `std::atomic_uint_least64_t`.


# Impact on implementations # {#implementation-impact}

The following table summarizes the affected standard library parts and the estimated effort
required to implement the proposed changes.
Entries rated "low / none" may require no changes at all, either because existing
implementations already support 128-bit integers, or would hypothetically support them
if only `std::is_integral_v` was `true` for an existing 128-bit type.

<table>
<tr>
    <th>Affected Library Part</th><th>Estimated Effort</th>
</tr>
<tr>
    <td>`std::to_integer`</td><td>low / none</td>
</tr>
<tr>
    <td>`<version>`</td><td>low</td>
</tr>
<tr>
    <td>`<limits>`</td><td>low</td>
</tr>
<tr>
    <td>`<climits>`</td><td>low</td>
</tr>
<tr>
    <td>`std::is_integral`</td><td>low</td>
</tr>
<tr>
    <td>`std::make_{un}signed`</td><td>low</td>
</tr>
<tr>
    <td>`std::cmp_xxx`</td><td>low / none</td>
</tr>
<tr>
    <td>`std::integer_sequence`</td><td>low / none</td>
</tr>
<tr>
    <td>`std::bitset::bitset`</td><td>low</td>
</tr>
<tr>
    <td>`std::bitset::to_u128`</td><td>low</td>
</tr>
<tr>
    <td>`<charconv>`</td><td>⚠️ high</td>
</tr>
<tr>
    <td>`<format>`</td><td>⚠️ high</td>
</tr>
<tr>
    <td>`<bit>`</td><td>⚠️ high</td>
</tr>
<tr>
    <td>`std::to_string`</td><td>low</td>
</tr>
<tr>
    <td>`std::iota_view`</td><td>❌ possible ABI break</td>
</tr>
<tr>
    <td>`std::gcd`, `std::lcm`</td><td>⚠️ high</td>
</tr>
<tr>
    <td>`std::midpoint`</td><td>low / none</td>
</tr>
<tr>
    <td>`std::xxx_sat`</td><td>low / none</td>
</tr>
<tr>
    <td>`std::saturate_cast`</td><td>low / none</td>
</tr>
<tr>
    <td>`<random>` generators</td><td>low / none</td>
</tr>
<tr>
    <td>`std::uniform_int_distribution`</td><td>low / none</td>
</tr>
<tr>
    <td>`std::seed_seq`</td><td>low / none</td>
</tr>
<tr>
    <td>`std::valarray`</td><td>depends on QoI</td>
</tr>
<tr>
    <td>`<cmath>` overloads</td><td>low</td>
</tr>
<tr>
    <td>`std::abs`</td><td>low</td>
</tr>
<tr>
    <td>`<linalg>`</td><td>depends on QoI</td>
</tr>
<tr>
    <td>`std::printf`, `std::scanf`</td><td>⚠️ high</td>
</tr>
<tr>
    <td>`std::atomic`</td><td>⚠️ high</td>
</tr>
</table>

## Microsoft ABI break for `std::ranges::iota_view::iterator::difference_type` ## {#iota-view-abi-break}

libc++ and libstdc++ define `std::ranges::iota_view<std::size_t>::iterator::difference_type`
to be `__int128`.
Since a `std::int_least128_t` alias would likely be defined as `__int128`, there is no ABI impact.

However, MSVC uses a class type `std::_Signed128`.
Even trivially copyable classes aren't passed via register in the Microsoft x86_64 ABI,
so this type is passed via the stack.

This may be undesirable for a future Microsoft 128-bit integer type.
A possible option would be to use the same ABI as `__int128`, which is to pass
results via `rdx` and `rax`.
It would also be possible to share an ABI with `__m128i`, which is to pass via `xmm` registers.

The ABI break stems from the fact that <code><i>IOTA-DIFF-T</i>(W)</code> for `W = std::size_t` is defined
to be:

> a signed integer type of width greater than the width of `W` if such a type exists.

Currently, no such type exists, but if `std::int_least128_t` did exist, it would no longer be valid
to use a class type as a `difference_type` in this case.
This would constitute an ABI break.
A possible solution which keeps ABI-compatibility is to reword this as:

> a signed <ins>standard</ins> integer type of width greater than the width of `W` if such a type exists.

This would still require `int` to have a difference type of say, `long`,
but `long long` would not be required to have a difference type of `std::int_least128_t`.

Issue: Feedback from Microsoft is needed regarding how to proceed with standardization.
If a pass-by-register ABI for 128-bit types is targeted, changes to <code><i>IOTA-DIFF-T</i></code> must be made.


# Design considerations # {#design-considerations}

The goal of this proposal is to obtain a mandatory 128-bit type with strong library support.
A `std::least_uint128_t` alias is the only option that does not involve any changes
to the core language.
Therefore, it is the obvious design choice for this proposal.

However, there are a few possible alternatives which were considered:

## Why no standard integer type? ## {#standard-integers}

One question that needs addressing is:

> Why standardize a `std::uint_least128_t` type alias but no standard integer type?
> Essentially, why no `unsigned long long long`?

Firstly, naming might be a problem here.
A standard integer type would likely warrant the ability to name it by keyword, and an
ever-increasing sequence of `long`s isn't an attractive solution.
Even with a concise keyword such as `_Uint128`, it is unclear what advantage such a keyword
would have over a type alias, other than saving one `#include` directive.

Secondly, it is useful to keep `std::uint_least128_t` a second-class citizen by not making it a
standard integer type.
This makes it possible to say that certain library facilities are only required to support
standard integer types, not extended integer types.
For example, the widening operations proposed in [[P3018R0]] could be required only to
take standard integer inputs, so that 128-bit integers don't also require 128-to-256-bit
widening operations.

Thirdly, as already stated in [[#c-compatibility]], C's `intmax_t` must be the
widest standard integer type.
To not break ABI and be C-compatible, `std::int_least128_t` must be
an extended integer type.

## Why no mandatory `std::int128_t` type? ## {#exact-width-integers}

Mandating any exact `std::intN_t` inadvertently restricts what size a byte can have
because exact-width types cannot have any padding.
`std::int128_t` implies that the width of a byte is a power of two &le; 128,
and historically, C++ has not restricted implementations to a specific byte size.

## Why no bit-precise integers? ## {#bit-precise-integers}

Instead of settling for 128-bit integers, it would also be possible to integrate
bit-precise integers (C's `_BitInt(N)` type) into the C++ standard.
Therefore, one may ask:

> Why don't we just standardize `_BitInt(N)` and introduce 128-bit integers that way?

In essence, this is asking:

> Why don't we just build a ten-lane highway instead of a cyclist path?

Firstly, this would be an enormously ambitious and time-intensive undertaking, with huge impact
on the standard.
Secondly, `_BitInt` does not satisfy the goals of this proposal for multiple reasons:

1. `_BitInt` in C23 isn't required to support 128 bits at all (see [[#c-library-support]]).
    Only 64 bits (or as much as `long long` is wide) are required.
    See [[#c-library-support]] for more details.
    In other words, `_BitInt` doesn't automatically give you 128-bit support.

2. It is not reasonable to expect full library support for any bit size.
    Even C doesn't require `_BitInt` support for its bit-manipulation functions, `printf`, and
    other utilities.
    The C++ standard library dwarfs that of C.
    It is even less realistic to expect full support from all C++ numeric functions,
    input/output facilities etc.
    However, it is realistic to extend library support to *just* 128 bits.

3. Even if library support for specifically 128-bit bit-precise integers was added,
    this would be very strange to specify in the standard.
    Perhaps `_BitInt(128)` would be treated differently from other bit-precise types and given more support from
    `std::format` and other functions, but this would be a somewhat arbitrary type, compared
    to standard integer types, which have minimum sizes, not exact sizes.
    Alternatively, support would be provided through a `_BitInt(N >= 128)` type, but to easily
    refer to it, one would need a `std::bit_int_least128_t` alias
    (Note that defining `int_least128_t = _BitInt(128)` would likely compromise C compatibility).
    At that point, we're just getting `std::int_least128_t` with extra steps.

4. `_BitInt` creates a parallel system to the existing standard and extended integer types.
    It would be highly unusual if the widening operations proposed in [[P3018R0]] could yield
    bit-precise integers for standard integer inputs.

### Summary of differences ### {#bitint-vs-uint128}

<table>
<tr>
    <th></th><th>Bit-precise integers</th><th>`std::int_least128_t`</td>
</tr>
<tr>
    <th>128-bit support mandatory</th><td>❌</td><td>✔️</td>
</tr>
<tr>
    <th>No core language changes</th><td>❌</td><td>✔️</td>
</tr>
<tr>
    <th>Extensive library support</th><td>❌</td><td>✔️</td>
</tr>
<tr>
    <th>Integrates easily into the<br>existing hierarchy of standard integers</th><td>❌</td><td>✔️</td>
</tr>
</table>

### C library support for bit-precise integers ### {#c-library-support}

The C23 standard currently does not mandate "full" library support for bit-precise integers.
For example, `printf` would require a `PRIuLEASTN` format specifier macro to print `uint_least128_t`,
but the existence of `_BitInt(128)` does not imply the existence of `uint_least128_t` or such
a macro.




# Implementation experience # {#implementation-experience}

## Existing 128-bit integer types ## {#existing-128-bit-integers}

### `__int128` ### {#existing-int-128}

GCC and clang already provide the 128-bit integer types in the form of
`__int128` and `unsigned __int128`.

### `std::_Signed128`, `std::_Unsigned128` ### {#existing-msvc-128}

The MSVC STL provides the class types `std::_Signed128` and `std::_Unsigned128` defined in
<a href="https://github.com/microsoft/STL/blob/main/stl/inc/__msvc_int128.hpp">`<__msvc_int128.hpp>`</a>.
These types implement all arithmetic operations and integer comparisons.

They satisfy the *integer-like* constraint and have been added to implement
[[P1522R1]].
`std::iota_view::difference_type` is possibly defined as `std::_Signed128`.


### `_BitInt(128)` ### {#existing-bit-int}

The C23 standard requires support for bit-precise integers
`_BitInt(N <= BITINT_MAXWIDTH)` where `BITINT_MAXWIDTH <= ULLONG_WIDTH`.
While this doesn't strictly force support for 128-bit integers,
GNU-family implementations support more than 128 bits already.

As of February 2024, the support is as follows:
<table>
<tr>
    <th>Compiler</th><th>`BITINT_MAXWIDTH`</th>
</tr>
<tr>
    <td>Clang 14</td><td>`128`</td>
<tr>
</tr>
    <td>Clang 16</td><td>`8388608`</td>
<tr>
</tr>
    <td>GCC 14</td><td>`65535`</td>
<tr>
</tr>
    <td>MSVC 19.38</td><td>❌</td>
</tr>
</table>

Note: Clang has supported `_BitInt` as an `_ExtInt` compiler extension prior to C standardization.

It is reasonable to expect that given enough time, `_BitInt(128)` will become
widely supported by existing implementations.


# Proposed wording # {#proposed-wording}

<style>
.indent {
    margin-left: 2em;
}

svg {
    background: none;
    vertical-align: middle;
}

ins {
    background: rgba(136, 255, 93, 0.2);
    color: inherit;
    text-decoration: underlined;
}
del {
    background: rgba(255, 93, 93, 0.2);
    color: inherit;
    text-decoration: strikethrough;
}
</style>

In subclause 17.3.2 [version.syn], update the feature-testing macros as follows:

<blockquote>
<pre>
<ins>#define __cpp_lib_atomic_int128 20XXXX</ins>
#define __cpp_lib_bitset <del>202306L</del><ins>20XXXX</ins>
<ins>#define __cpp_lib_bitset_int128 20XXXX</ins>
<ins>#define __cpp_lib_int128        20XXXX</ins>
</pre>
</blockquote>

In subclause 17.4.1 [cstdint.syn], update the synopsis as follows:

<blockquote>
<pre>
// all freestanding
namespace std {
  using int8_t          = <i>signed integer type</i>;   // optional
  using int16_t         = <i>signed integer type</i>;   // optional
  using int32_t         = <i>signed integer type</i>;   // optional
  using int64_t         = <i>signed integer type</i>;   // optional
  <ins>using int128_t        = <i>signed integer type</i>;   // optional</ins>
  using intN_t          = <i>see below</i>;             // optional

  using int_fast8_t     = <i>signed integer type</i>;
  using int_fast16_t    = <i>signed integer type</i>;
  using int_fast32_t    = <i>signed integer type</i>;
  using int_fast64_t    = <i>signed integer type</i>;
  <ins>using int_fast128_t   = <i>signed integer type</i>;</ins>
  using int_fastN_t     = <i>see below</i>;             // optional

  using int_least8_t    = <i>signed integer type</i>;
  using int_least16_t   = <i>signed integer type</i>;
  using int_least32_t   = <i>signed integer type</i>;
  using int_least64_t   = <i>signed integer type</i>;
  <ins>using int_least128_t  = <i>signed integer type</i>;</ins>
  using int_leastN_t    = <i>see below</i>;             // optional

  using intmax_t        = <i>signed integer type</i>;
  using intptr_t        = <i>signed integer type</i>;   // optional

  using uint8_t         = <i>unsigned integer type</i>; // optional
  using uint16_t        = <i>unsigned integer type</i>; // optional
  using uint32_t        = <i>unsigned integer type</i>; // optional
  using uint64_t        = <i>unsigned integer type</i>; // optional
  <ins>using uint128_t       = <i>unsigned integer type</i>; // optional</ins>
  using uintN_t         = <i>see below</i>;             // optional

  using uint_fast8_t    = <i>unsigned integer type</i>;
  using uint_fast16_t   = <i>unsigned integer type</i>;
  using uint_fast32_t   = <i>unsigned integer type</i>;
  using uint_fast64_t   = <i>unsigned integer type</i>;
  <ins>using uint_fast128_t  = <i>unsigned integer type</i>;</ins>
  using uint_fastN_t    = <i>see below</i>;             // optional

  using uint_least8_t   = <i>unsigned integer type</i>;
  using uint_least16_t  = <i>unsigned integer type</i>;
  using uint_least32_t  = <i>unsigned integer type</i>;
  using uint_least64_t  = <i>unsigned integer type</i>;
  <ins>using uint_least128_t = <i>unsigned integer type</i>;</ins>
  using uint_leastN_t   = <i>see below</i>;             // optional

  using uintmax_t       = <i>unsigned integer type</i>;
  using uintptr_t       = <i>unsigned integer type</i>; // optional
}
</pre>
</blockquote>

In subclause 17.4.1 [cstdint.syn], update paragraph 3 as follows:

<blockquote>
All types that use the placeholder *N* are optional when *N* is not
`8`, `16`, `32`, <del>or</del> `64`<ins>, or `128`</ins>.
The exact-width types `intN_t` and `uintN_t` for *N* =
`8`, `16`, `32`, <del>and</del> `64`<ins>, and `128`</ins>
are also optional; [...]
</blockquote>

In subclause 22.9.2.1 [template.bitset.general], update the synopsis as follows:
<blockquote>
<pre>
    // [bitset.cons], constructors
    constexpr bitset() noexcept;
<del>    constexpr bitset(unsigned long long val) noexcept;</del>
<ins>    constexpr bitset(<i>unsigned-integer-least-llong</i> val) noexcept;</ins>
[...]
    constexpr unsigned long        to_ulong() const;
    constexpr unsigned long long   to_ullong() const;
<ins>    constexpr uint_least128_t to_least128() const;</ins>
<ins>    constexpr uint_fast128_t  to_fast128() const;</ins>
</pre>
</blockquote>

In subclause 22.9.2.2 [template.bitset.const], update the constructors as follows:
<blockquote>
<pre>
<del>constexpr bitset(unsigned long long val) noexcept;</del>
<ins>constexpr bitset(<i>unsigned-integer-least-llong</i> val) noexcept;</ins>
</pre>
<p class="indent">
<ins>2 The implementation provides one overload for every unsigned integer type whose
conversion rank is that of `int` or greater.</ins>
</p>
<p class="indent">
<del>2</del><ins>3</ins> *Effects*: Initializes the first `M` bit positions to the corresponding bit values in val.
`M` is the smaller of `N` and the number of bits in the value representation
([basic.types.general]) of <del>`unsigned long long`</del><ins>the type of `val`</ins>.
If `M < N`, the remaining bit positions are initialized to zero.
</p>
</blockquote>

Note: It is possible that `unsigned long long` is the same type
as `uint_least128_t`, so the mandate is necessary to prevent a duplicate definition.

In subclause 22.9.2.3 [bitset.members], make the following changes:

<blockquote>
<pre>
<del>constexpr unsigned long to_ulong() const;</del>
</pre>
<p class="indent">
<del>*Returns*: `x`.</del>
</p>
<p class="indent">
<del>*Throws*: `overflow_error` if the integral value `x` corresponding to the bits in `*this`
cannot be represented as type `unsigned long`.</del>
</p>
<pre>
<del>constexpr unsigned long long to_ullong() const;</del>
<ins>constexpr unsigned long      to_ulong() const;</ins>
<ins>constexpr unsigned long long to_ullong() const;</ins>
<ins>constexpr uint_least128_t    to_least128() const;</ins>
<ins>constexpr uint_fast128_t     to_fast128() const;</ins>
</pre>
<p class="indent">
*Returns*: `x`.
</p>
<p class="indent">
*Throws*: `overflow_error` if the integral value `x` corresponding to the bits in `*this`
cannot be represented as <del>type `unsigned long long`</del><ins>the return type</ins>.
</p>
<pre>
</blockquote>

Issue: Wording for `<format>` is W.I.P.

Wording for `to_string` requires no changes after [[Schultke1]].
However, should those changes not be accepted,
update subclause 23.4.2 [string.syn] as follows:

<blockquote>
<pre>
<del>
  string to_string(int val);
  string to_string(unsigned val);
  string to_string(long val);
  string to_string(unsigned long val);
  string to_string(long long val);
  string to_string(unsigned long long val);
  string to_string(int_least128_t);</del>
<ins>  string to_string(<i>integer-least-int</i> val);</ins>
  string to_string(float val);
  string to_string(double val);
  string to_string(long double val);
</pre>
</blockquote>

Under the same condition, in subclause 23.4.5 [string.conversions], update `to_string`:
<blockquote>
<pre>
<del>  string to_string(int val);
  string to_string(unsigned val);
  string to_string(long val);
  string to_string(unsigned long val);
  string to_string(long long val);
  string to_string(unsigned long long val);</del>
<ins>  string to_string(<i>integer-least-int</i> val);</ins>
  string to_string(float val);
  string to_string(double val);
  string to_string(long double val);
</pre>
<p class="indent">
<ins>The implementation provides one overload for every integer type whose
conversion rank is that of `int` or greater.</ins>
</p>
<p class="indent">
7 *Returns*: `format("{}", val)`.
</p>
</blockquote>

In subclause 28.7.1 [cmath.syn], update the synopsis as follows:
<blockquote>
<pre>
  // [c.math.abs], absolute values
<del>  constexpr int abs(int j);                                             // freestanding
  constexpr long int abs(long int j);                                   // freestanding
  constexpr long long int abs(long long int j);                         // freestanding</del>
<ins>  constexpr auto abs(<i>signed-integer-least-int</i> j) -> decltype(j);        // freestanding</ins>
  constexpr <i>floating-point-type</i> abs(<i>floating-point-type</i> j);             // freestanding-deleted
</pre>
</blockquote>

In subclause 28.7.2 [c.math.abs], make the following changes:
<blockquote>
<pre>
<del>constexpr int abs(int j);
constexpr long int abs(long int j);
constexpr long long int abs(long long int j);</del>
<ins>constexpr auto abs(<i>signed-integer-least-int</i> j) -> decltype(j);</ins>
</pre>
<p class="indent">
<ins>The implementation provides one overload for every signed integer type whose
conversion rank is that of `int` or greater.</ins>
</p>
<p class="indent">
<del>*Effects*: These functions have the semantics specified in the C standard library for the functions `abs`, `labs`, and `llabs`, respectively.</del>
<ins>*Returns*: `j >= 0 ? j : -j;`.
</p>
</blockquote>

Issue: Wording for `std::atomic<std::int_least128_t>` is W.I.P.

<pre class=biblio>
{
    "N3047": {
        "title": "N3047 working draft — August 4, 2022 ISO/IEC 9899:2023 (E)",
        "href": "https://www.iso-9899.info/n3047.html",
        "authors": ["ISO"]
    },
    "Schultke1": {
        "title": "Better, constexpr to_string",
        "href": "https://eisenwave.github.io/cpp-proposals/constexpr-to-string.html",
        "authors": ["Jan Schultke"]
    }
}
</pre>