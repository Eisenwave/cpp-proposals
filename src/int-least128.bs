<pre class='metadata'>
Title: <code>std::int_least128_t</code>
Shortname: Pxxxx
Revision: 0
Status: NP
Date: 2024-02-05
Group: WG21
Audience: LEWGI, LWG
Editor: Jan Schultke, janschultke@gmail.com
ED: https://eisenwave.github.io/cpp-proposals/int-least128.html
!Source: [eisenwave/cpp-proposals](https://github.com/Eisenwave/cpp-proposals/blob/master/src/int-least128.bs)
Markup Shorthands: markdown on
Abstract: This proposal standardizes 128-bit integers.
</pre>


# Introduction # {#introduction}

128-bit integers have countless practical uses, and are already implemented in the form of compiler
extensions such as `__int128`, and the C23 standard type `_BitInt(128)`.

This paper seeks to standardize the existing practice of providing 128-bit integers.
The goal is to obtain a mandatory 128-bit integer type with no core language changes
and strong support from the C++ standard library.
To accomplish this, the mandatory aliases `std::int_least128_t` and `std::uint_least128_t`
are proposed.

While the definition of these aliases is trivial, requiring them also implies
library support from `<format>`, `<bit>`, `<cmath>`, `<limits>`, and other facilities.
Such library support is crucial for a fully-fledged and useful 128-bit type.
[[##library-impact]] demonstrates that the necessary support is not overwhelming
to implement.

Note: The implementation optionally provides `std::int128_t` and `std::uint128_t` aliases.




# Motivation and scope # {#motivation-and-scope}

There are two essential reasons for standardizing a 128-bit integer type:

1. 128-bit integers are extremely useful in a variety of domains.

2. 128-bit integers are already implemented in multiple compilers, and quasi-mandated by the C23
    standard through the `_BitInt(128)` and `unsigned _BitInt(128)` types.
    That is, if the implementation defines `BITINT_MAXWIDTH >= 128`.
    Therefore, this proposal is merely standardizing existing practice.

For some readers, there may be an obvious question on their mind:

> If 128-bit integers are so useful, why haven't they been proposed sooner?

One significant problem which has been brought up historically is C's `intmax_t`, which had been
the widest integer type.
Introducing a wider integer would be an ABI break because to comply with the C standard wording,
`intmax_t` would need to be 128-bit as well.
This restriction was lifted in C23, allowing `intmax_t` to be only as wide as `long long`.
C++ inherits this "relaxed" `std::intmax_t`.
See [[#c-compatibility]] for more details.

## Use cases ## {#use-cases}

To motivate this proposal, I will briefly introduce a few use cases of 128-bit integers.

### Cryptography ### {#cryptography}

128-bit integers are commonly used in many cryptographic algorithms:

- Most notably, AES-128 uses a 128-bit key size.
    AES variants with wider key sizes still use a block size of 128 bits.
- Various other block ciphers such as Twofish and Serpent also have key and/or block sizes of 128 bits.
- MD5 hashes produce 128-bit output.
- SHA-2 and SHA-3 produce outputs beyond 128-bit, but outputs can be truncated to 128-bit,
    or represented as a pair/array of 128-bit integers.

### Random number generation ### {#random-number-generation}

Some random number generators produce 128-bit numbers.

For example, the CSRPNG (cryptographically secure pseudo-random number generator)
Fortuna uses a block cipher to produce random numbers.
When a 128-bit block cipher is used, the output is naturally 128-bit as well.
Fortuna is used in the implementation of `/dev/random` in FreeBSD 11, and in AppleOSes since 2020.

### Widening operations ### {#widening-operations}

[[P3018R0]] proposed widening operations which yield an integer with double the width of the input.
An obvious issue is that the language provides no 128-bit integer type, so the widening
operations for 64-bit operands could not exist, or would return a type which is not
considered an integer.

Note: Extended integer types require extensive library support, so the implementation couldn't
      simply return an extended 128-bit integer type without sufficiently supporting such at type.

This obstacle is especially unfortunate considering that hardware often supports 64-to-128-bit
widening operations directly.
For example:

- The x86 `mul` (unsigned multiply) instruction stores the result of a 64-bit multiplication
    in the register pair `rdx:rax`.
- RISC-V provides the `clmul` and `clmulh` instructions to compute the low and high part of a
    carry-less multiplication.
    In fact, x86, ARM, and RISC-V all provide a way to compute a carry-less 128-bit product. 

Some operating systems also provide 128-bit operations.
For example, the Windows API provides a `Multiply128` function.

### Multi-precision operations ### {#multi-precision-operations}

For various applications (cryptography, various numeric applications, etc.) arithmetic with
large bit sizes is required.
For example, the RSA (Rivest–Shamir–Adleman) cryptosystem typically uses bit sizes of 2048 or 4096.

This involves addition, multiplication, and division with multi-precision integers, which is
implemented digit-by-digit.
For example, to implement multiplication,
the number can be split into 32-bit or 64-bit digits, and long multiplication can be performed,
where the high part of the multiplication could be obtained from the high 64-bits of a 128-bit
result.

Note: Such a widened 128-bit result could be obtained through [[#widening-operations]] operations.

### Double-wide atomic operations ### {#double-wide-atomic-operations}

Some architectures provide double-wide atomic operations.
For example, x86_64 provides a `cmpxchg16b` instruction which can be used to implement a
128-bit `std::atomic::compare_exchange_strong`.

Such an operation is useful for lock-free data structures, where a simple CAS is often insufficient
because two 64-bit pointers or a 64-bit pointer with some metadata have to be compared and swapped
simultaneously.

To be fair, this operation is already exposed through `std::atomic<std::array<std::byte, 16>>`,
so 128-bit atomic integers aren't strictly necessary except for 128-bit `.fetch_xxx` operations,
though those don't have direct hardware support.

### High-precision clocks ### {#high-precision-clocks}

64-bit integers are somewhat insufficient for high-precision clocks, if large time spans should
also be covered.
When counting nanoseconds, a maximum value of 2<sup>63</sup>-1 can only represent approximately
9 billion seconds, or 7020 years.

This makes 64-bit integers insufficient for some time calculations, where 128-bit integers
would suffice.
Alternatively, 64-bit floating-point numbers can provide a reasonable trade-off.

### Floating-point operations ### {#floating-point-operations}

The implementation of IEEE 754/IEC-559 floating-point operations often involves examining the
bit-representation of the floating-point number through an unsigned integer.

The C++ standard provides `std::float128_t`, but no matching 128-bit integer type,
which makes this more difficult.

### Financial systems ### {#financial-systems}

128-bit integers can be used to represent huge monetary values.
For example, the smallest fraction of a Bitcoin is a Satoshi, where one Bitcoin equals
a million Satoshis.
A signed 64-bit integer can only losslessly represent approximately 10<sup>13</sup> Bitcoins.

### Database systems ### {#database-systems}

A 128-bit integer can be used to represent a UUID (Universally Unique Identifier).
While 64-bit integers are often sufficient as a unique identifier, it is quite likely that two
identical identifiers are chosen by a random number generator over a long period of time,
especially considering the Birthday Paradox.
Therefore, at least 128 bits are typically used for such applications.

### Networking ### {#networking}

IPv6 addresses can be represented as a 128-bit integer.
This may be a convenient representation because bitwise operations for masking and accessing
individual bits or bit groups may be used, and implementing these is much easier using a 128-bit
integer compared to multi-precision operations using two 64-bit integers.


# Impact on the standard # {#impact-on-the-standard}

First and foremost, this proposal mandates the following integer types in `<cstdint>`:
```cpp
using int_least128_t  = /* signed integer type */;
using uint_least128_t = /* unsigned integer type */;

using int_fast128_t   = /* signed integer type */;
using uint_fast128_t  = /* unsigned integer type */;

using int128_t = /* signed integer type */; // optional
using uint128_t = /* unsigned integer type */; // optional

// The corresponding macros for MIN and MAX must also be defined ...
```
This change in itself is almost no change at all.
The implementation can already provide `int_least128_t` while complying with the C++11 standard.
However, this change has far-reaching ramifications which are examined below.

## C Compatibility ## {#c-compatibility}

Any attempt of standardizing 128-bit integers must also keep possible compatibility with the C
standard in mind.
C does not guarantee a `int_least128_t` alias, but `intmax_t` may present a potential point of
conflict.

[[N3047]], 7.22.1.5 [Greatest-width integer types] currently defines `intmax_t` as follows:

<blockquote>
The following type designates a signed integer type, other than a bit-precise integer type, capable of
representing any value of any signed integer type with the possible exceptions of signed bit-precise
integer types and of signed extended integer types that are wider than `long long` and that are
referred by the type definition for an exact width integer type:
```cpp
intmax_t
```
</blockquote>

For `intmax_t` to not be `int_least128_t` in the C standard, there must exist an `int128_t`
alias for the same type.
GCC already provides an `__int128` type which satisfies the padding-free requirement and could
be exposed as `int128_t`.

In conclusion, it is possible to mandate a `std::int_least128_t` alias without sacrificing
C-compatibility.


## Impact on the core language ## {#core-impact}

The proposal makes no changes to the core language.
However, it is worth noting that the existence of `std::uint_least128_t` leads to some oddities:

- The result of the `sizeof` operator can be a 128-bit integer.
- The underlying type of enumerations can be a 128-bit integer.
- Previously ill-formed integer literals could now be of 128-bit integer type.
- The conditions in `#if` preprocessing directives are evaluated as if operands had the same
    representation as `intmax_t` or `uintmax_t`,
    which means that 128-bit integers cannot be used in this context, or the values
    would be truncated.

However, none of this is a new issue introduced by this proposal.
Any compliant implementation could already have produced this behavior,
assuming it supported 128-bit integers as an optional extended integer type.

While there is certainly software which relies on `std::size_t` and other types not exceeding
64 bits, not defining `std::size_t` to be a 128-bit type is a QoI (Qualify of Implementation) issue.
Such problems are not within the scope of the standard, and I don't see it as necessary
to add Recommended Practice paragraphs as protection against malicious implementations.


## Impact on the library ## {#library-impact}

To properly integrate 128-bit integers into the standard, it is also necessary to provide
library support.
What use is a standard 128-bit integer if it cannot be turned into a string or used in any of the
standard library math functions?

Find below a summary of issues that arise from the introduction of 128-bit integers in the
C++ standard library.
One common issue is that aliases such as `size_type` and `difference_type` within
containers, iterators, and other types can be a 128-bit integer.
Whether to define them as such is a QoI issue in general, and won't be discussed further.

### Language support library ### {#library-impact-language-support}

**Issue:** Certain type aliases such as `ptrdiff_t` and `size_t` could now be defined as a 128-bit type.<br>
**Action:** ✔️ No impact on the standard.
Whether to do so is a QoI issue.

**Issue:** `std::to_integer` would need 128-bit support.<br>
**Action:** ✔️ No impact on the standard.

Note: An implementation is trivial.
      `std::to_integer` is equivalent to a single `static_cast`.

**Issue:** `<version>` would likely need a 128-bit integer feature-testing macro.<br>
**Action:** ⚠️ Add a macro.

**Issue:** `<numeric_limits>` would need a trait for 128-bit integers.<br>
**Action:** ✔️ No impact on the standard; require a `std::numeric_limits` specialization.

Note: GCC already provides `std::numeric_limits<__int128>` as an extension.

**Issue:** `<climits>` would need additional constants for 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

**Issue:** `<cstdint>` would need need to explicitly require support for 128-bit integers
in its synopsys.<br>
**Action:** ⚠️ Define aliases such as `int_least128_t` and explicitly state that 128 bits are supported.

### Metaprogramming library ### {#library-impact-metaprogramming}

**Issue:** `std::is_integral` needs to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: GCC already implements `std::is_integral<__int128>`.
Implementing this trait is not difficult in general.

**Issue:** `std::rank<T>::value` could be a 128-bit integer.<br>
**Action:** ✔️ No impact on the standard.

Note: This depends on whether `std::size_t` is a 128-bit integer, and this decision is QoI.

**Issue:** `std::make_signed` and `std::make_unsigned` require 128-bit support.<br>
**Action:** ✔️ No impact on the standard.
GCC already implements `std::make_{un}signed<__int128>`.

**Issue:** `std::ratio` currently accepts non-type template arguments of `std::intmax_t`.
`std::intmax_t` is no longer the widest integer type and changing the type of NTTP to
`std::uint_least128_t` would be an ABI break because the type of template argument participates
in name mangling.<br>
**Action:** ✔️ No impact on the standard.

Note: Unfortunately ratios beyond 2<sup>64</sup> or 2<sup>-64</sup>
cannot be represented, assuming that `std::intmax_t` is a 64-bit integer.

### General utilities library ### {#library-impact-utilities}

**Issue:** Integer comparison functions (`std::cmp_equal` et al.) require 128-bit support.
**Action:** ✔️ No impact on the standard.
Existing implementations are generic and could support 128-bit integers with no changes.

**Issue:** `std::integer_sequence` would need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: The implementation of `std::integer_sequence` or `std::make_integer_sequence` does not depend
on a specific integer width.

**Issue:** `std::bitset` could receive an additional constructor taking `std::uint_least128_t`.<br>
**Action:** ⚠️ Add such a constructor.

**Issue:** `std::bitset` could receive an additional `to_u128` function, similar to `to_ullong`.<br>
**Action:** ⚠️ Add such a function.

**Issue:** `std::to_chars` and `std::from_chars` would need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: 128-bit stringification can be implemented in terms of one to three 64-bit stringifications
      and integer divisions with constant divisor.
      In the special case where the base of conversion is a power of two, no integer division is
      needed, and a 64-bit implementation can be repurposed.

**Issue:** `<format>` facilities need to support 128-bit integers.<br>
**Action:** ⚠️ To be investigated.

Note: The locale-independent forms are simply implemented in terms of `std::to_chars` and are not
affected.
However, it needs to be clear whether locale support for 128-bit integers would constitute
an ABI break.

**Issue:** `basic_format_parse_context::check_dynamic_spec` and `basic_format_parse_context::check_dynamic_spec_integral` could possibly support 128-bit integers.<br>
**Action:** ⚠️ Add support for 128-bit integers.
This is not an ABI break.

**Issue:** `basic_format_arg` may need direct support for 128-bit integers rather than using the
fallback case of initializing a value with `handle(v)`.<br>
**Action:** ⚠️ To be investigated.

**Issue:** Bit manipulation functions in `<bit>` need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: For most functions, a 128-bit implementation simply combines the results of calling the 64-bit
variant for the low and high bits.
For example, `popcount(std::uint128_t x)` returns
`popcount<std::uint64_t>(x >> 64) + popcount<std::uint64_t>(x)`.

**Issue:** It would be convenient if `std::to_string` support 128-bit types.<br>
**Action:** ⚠️ Support should be provided.
However, this issue is dealt with in [[Schultke1]], not in this proposal.

### Containers library ### {#library-impact-containers}

**Issue:** The extents and index types of `std::mdspan` could be 128-bit integers.
This is also the case for type aliases of `std::strided_slice`.
The exposition-only helper <code><i>integral-constant-like</i></code> now also includes
128-bit integers.<br>
**Action:** ✔️ No impact on the standard.
All these issues are either QoI or don't impact existing implementations substantially.

### Iterators library ### {#library-impact-iterators}

**Issue:** The exposition-only helper <code><i>integral-constant-like</i></code> now also includes
128-bit integers.
Generally, 128-bit integers would be a valid `difference_type` and an implementation needs to
consider this when defining concepts that use integers in any way.<br>
**Action:** ✔️ No impact on the standard.

Note: As long as `std::is_integral` (and by proxy, `std::integral`) is correct, the existing wording
should be unaffected.


### Ranges library ### {#library-impact-ranges}

**Issue:** `std::iota_view<W>::iterator::difference_type` where `W` is an integral type is defined to be
a wider integer type if such a type exists, and `iter_difference_t<W>` is not wider.
This causes an issue for existing implementations that don't consider 128-bit integers to exist,
and for `W = std::uint_least128_t`, this may necessitate a &ge; 129-bit integer.
Similarly, `std::repeat_view::iterator::difference_type` is affected.<br>
**Action:** ⚠️ To be investigated.

**Issue:** `std::cartesian_product_view::size` may now return a 128-bit integer.
The standard recommends to use a type which is sufficiently wide to store the product
of sizes of underlying ranges.
A similar issue arises for `std::cartesian_product_view::iterator`.<br>
**Action:** ✔️ No impact on the standard.

Note: The choice of integer type used to be (and still is) implementation-defined.


### Algorithms library ### {#library-impact-algorithms}

**Issue:** `std::gcd`, `std::lcm`, and `std::midpoint` need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: For GCD computation, algorithms which don't rely on integer division exist, such as Binary GCD.
Therefore, a reasonably fast 128-bit version is possible.
`std::midpoint` can be implemented in a width-agnostic way.

**Issue:** Saturating arithmetic functions and `saturate_cast` need to support 128-bit integers.
**Action:** ✔️ No impact on the standard.

Note: Existing 64-bit implementations that don't rely on 128-bit types can be equally used for 128-bit
types.

### Numerics library ### {#library-impact-numerics}

**Issue:** Various random number generators and `std::uniform_int_distribution` need to support
128-bit types.<br>
**Action:** ✔️ No impact on the standard.

Note: The implementation of random number generators does not usually rely on bit widths being lower
than 128-bit.
Some generators such as linear congruential engines rely heavily on modulo division,
which is very expensive for 128-bit integers.
However, this can be simplified to fixed-point multiplication and bit-shifting for a known modulo,
which is always the case in generators, though not in distributions.

**Issue:** `std::seed_seq` needs to support `std::initializer_list<std::uint128_t>`.<br>
**Action:** ✔️ No impact on the standard.

Note: This can be implemented by splitting each 128-bit integer into two 64-bit integers and
repurposing and existing implementation.

**Issue:** `std::valarray` needs to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: `std::valarray` does not rely on using integer types specifically.
Treating 128-bit integers specially and utilizing hardware resources is a QoI issue.

**Issue:** For most `<cmath>` functions, an additional overload taking 128-bit integers would
need to be defined.<br>
**Action:** ✔️ No impact on the standard.

Note: The overload taking `std::uint_least128_t` would convert to `double`, like other functions.
`double` is more than enough to represent the maximum 128-bit integer value, however,
it should be considered whether `long double` should be used to minimize loss of precision.

**Issue:** `std::abs` should receive an additional 128-bit overload.<br>
**Action:** ⚠️ Add an overload `std::uint_least128_t abs(std::uint_least128_t)`.

Note: Without such an overload, `std::uint_least128_t` would delegate to `abs(double)`.

**Issue:** The `<linalg>` library may need 128-bit support.<br>
**Action:** ✔️ No impact on the standard.

Note: The linear algebra library operates on `std::mdspan` of any type.
Treating 128-bit integers specially and utilizing hardware resources is a QoI issue.

### Time library ### {#library-impact-time}

**Issue:** Significant portions of `<chrono>` use `std::ratio`, which has `std::intmax_t` template
parameters.<br>
**Action:** ✔️ No impact on the standard.

<div class="note">
<span class="marker">Note:</span>
`std::ratio` cannot represent certain extreme ratios
if `std::intmax_t` is narrower than `std::uint_least128_t`.
However, the time library is generally safe to use, even if the representation of say,
`std::duration` is wider than the types used in a `std::ratio` fraction.
      
If there is future interest, types such as `std::duration`
could be relaxed to work with *ratio-like* types,
so that a new 128-bit `std::ratio`-style type could be used as well,
not just `std::ratio` itself.
However, this is a significant extension of the time library and not part of this proposal.
</div>

### Localization library ### {#library-impact-localization}

**Issue:** `std::num_get` and `std::num_put` could use `std::uint_least128_t` overloads for `do_get`.<br>
**Action:** ✔️ No impact on the standard.

Note: This would be a an ABI break if changes were made.
`std::format` and `std::print` provide sufficient alternatives which can be supported without
breaking ABI.

### Input/output library ### {#library-impact-io}

**Issue:** `std::num_get` and `std::num_put` don't support 128-bit integers.
By proxy, extraction and insertion with `operator>>` would not work.<br>
**Action:** ✔️ No impact on the standard.

Note: The standard doesn't require these to work for all integer types, only for standard integer types.
Any change would be an ABI break, so these facilities could be left untouched.
Unfortunately, the user won't be able to `std::cout << std::uint_least128_t{...}`, however,
the language provides sufficient alternatives.

**Issue:** `std::printf` and `std::scanf` need to support 128-bit integers.<br>
**Action:** ✔️ No impact on the standard.

Note: If `std::to_chars` and `std::format` are already mandated, it is reasonable to expect `std::printf`
support as well.
`PRIoLEAST128` would also need to be defined, but this has no impact on the existing wording.


### Concurrency support library ### {#concurrency-support-library}

**Issue:** `std::atomic` needs to support `std::uint_least128_t`.<br>
**Action:** ✔️ No impact on the standard.

Note: `std::atomic` specializations are already defined for all integer types.
On x86_64, all `.fetch` operations would fall back onto CAS-and-retry loops
utilizing the `cmpxchg16b` instruction.
This would be no better than using a `std::atomic<std::array<std::byte, 16>>`.
However, these are generally QoI issues and there is no restriction that would prevent
`std::atomic<std::int_least128_t>` specializations, even if hardware support is very limited.

**Issue:** There should be additional aliases `std::atomic_uint_least128_t` et al. aliases.<br>
**Action:** ⚠️ Define aliases following the same convention as `std::atomic_uint_least64_t`.





# Design considerations # {#design-considerations}

The goal of this proposal is to obtain a mandatory 128-bit type with strong library support.
A `std::least_uint128_t` alias is the only option that does not involve any changes
to the core language.
Therefore, it is the obvious design choice for this proposal.

However, there are a few possible alternatives which were considered:

## Why no standard integer type? ## {#standard-integers}

One question that needs addressing is:

> Why standardize a `std::uint_least128_t` type alias but no standard integer type?
> Essentially, why no `unsigned long long long`?

Firstly, naming might be a problem here.
A standard integer type would likely warrant the ability to name it by keyword, and an
ever-increasing sequence of `long`s isn't an attractive solution.
Even with a concise keyword such as `_Uint128`, it is unclear what advantage such a keyword
would have over a type alias, other than saving one `#include` directive.

Secondly, it is useful to keep `std::uint_least128_t` a second-class citizen by not making it a
standard integer type.
This makes it possible to say that certain library facilities are only required to support
standard integer types, not extended integer types.
For example, the widening operations proposed in [[P3018R0]] could be required only to
take standard integer inputs, so that 128-bit integers don't also require 128-to-256-bit
widening operations.

Thirdly, as already stated in [[#c-compatibility]], C's `intmax_t` must be the
widest standard integer type.
To not break ABI and be C-compatible, `std::int_least128_t` must be
an extended integer type.

## Why no mandatory `std::int128_t` type? ## {#exact-width-integers}

Mandating any exact `std::intN_t` inadvertently restricts what size a byte can have
because exact-width types cannot have any padding.
`std::int128_t` implies that the width of a byte is a power of two &le; 128,
and historically, C++ has not restricted implementations to a specific byte size.

## Why no bit-precise integers? ## {#bit-precise-integers}

Instead of settling for 128-bit integers, it would also be possible to integrate
bit-precise integers (C's `_BitInt(N)` type) into the C++ standard.
Therefore, one may ask:

> Why don't we just standardize `_BitInt(N)` and introduce 128-bit integers that way?

In essence, this is asking:

> Why don't we just build a ten-lane highway instead of a cyclist path?

Firstly, this would be an enormously ambitious and time-intensive undertaking, with huge impact
on the standard.
Secondly, `_BitInt` does not satisfy the goals of this proposal for multiple reasons:

1. `_BitInt` in C23 isn't required to support 128 bits at all (see [[#c-library-support]]).
    Only 64 bits (or as much as `long long` is wide) are required.
    See [[#c-library-support]] for more details.
    In other words, `_BitInt` doesn't automatically give you 128-bit support.

2. It is not reasonable to expect full library support for any bit size.
    Even C doesn't require `_BitInt` support for its bit-manipulation functions, `printf`, and
    other utilities.
    The C++ standard library dwarfs that of C.
    It is even less realistic to expect full support from all C++ numeric functions,
    input/output facilities etc.
    However, it is realistic to extend library support to *just* 128 bits.

3. Even if library support for specifically 128-bit bit-precise integers was added,
    this would be very strange to specify in the standard.
    Perhaps `_BitInt(128)` would be treated differently from other bit-precise types and given more support from
    `std::format` and other functions, but this would be a somewhat arbitrary type, compared
    to standard integer types, which have minimum sizes, not exact sizes.
    Alternatively, support would be provided through a `_BitInt(N >= 128)` type, but to easily
    refer to it, one would need a `std::bit_int_least128_t` alias
    (Note that defining `int_least128_t = _BitInt(128)` would likely compromise C compatibility).
    At that point, we're just getting `std::int_least128_t` with extra steps.

4. `_BitInt` creates a parallel system to the existing standard and extended integer types.
    It would be highly unusual if the widening operations proposed in [[P3018R0]] could yield
    bit-precise integers for standard integer inputs.

### Summary of differences ### {#bitint-vs-uint128}

<table>
<tr>
    <th></th><th>Bit-precise integers</th><th>`std::int_least128_t`</td>
</tr>
<tr>
    <th>128-bit support mandatory</th><td>❌</td><td>✔️</td>
</tr>
<tr>
    <th>No core language changes</th><td>❌</td><td>✔️</td>
</tr>
<tr>
    <th>Extensive library support</th><td>❌</td><td>✔️</td>
</tr>
<tr>
    <th>Integrates easily into the<br>existing hierarchy of standard integers</th><td>❌</td><td>✔️</td>
</tr>
</table>


### C library support for bit-precise integers ### {#c-library-support}

The C23 standard currently does not mandate "full" library support for bit-precise integers.
For example, `printf` would require a `PRIuLEASTN` format specifier macro to print `uint_least128_t`,
but the existence of `_BitInt(128)` does not imply the existence of `uint_least128_t` or such
a macro.




# Implementation experience # {#implementation-experience}

GCC and clang already provide 128-bit integers in the form of a `__int128` type.

Furthermore, any implementation of the C23 standard must also support
`_BitInt(N <= BITINT_MAXWIDTH)` where `BITINT_MAXWIDTH <= ULLONG_WIDTH`.
While this doesn't strictly force support for 128-bit integers, clang &le; 15 supports
`BITINT_MAXWIDTH == 128`, and clang &ge; 16 even provides support for more than 128 bits.

It is reasonable to expect any C23 implementation to provide at least 128-bit-precise support,
and by proxy, pave the way for 128-bit extended integers.




# Proposed wording # {#proposed-wording}

<style>
.indent {
    margin-left: 2em;
}

svg {
    background: none;
    vertical-align: middle;
}

ins {
    background: rgba(136, 255, 93, 0.2);
    color: inherit;
    text-decoration: none;
}
del {
    background: rgba(255, 93, 93, 0.2);
    color: inherit;
    text-decoration: strikethrough;
}
</style>

WIP

<pre class=biblio>
{
    "N3047": {
        "title": "N3047 working draft — August 4, 2022 ISO/IEC 9899:2023 (E)",
        "href": "https://www.iso-9899.info/n3047.html",
        "authors": ["ISO"]
    },
    "Schultke1": {
        "title": "Better, constexpr to_string",
        "href": "https://eisenwave.github.io/cpp-proposals/constexpr-to-string.html",
        "authors": ["Jan Schultke"]
    }
}
</pre>